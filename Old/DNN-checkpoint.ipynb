{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accredited-iraqi",
   "metadata": {},
   "source": [
    "Code for loading data, creating the network and training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-meaning",
   "metadata": {},
   "source": [
    "## Loading and Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "silver-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MagicTools as mt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdflist = []\n",
    "potlist = []\n",
    "for i in range(1,31):\n",
    "    for j in range(10):\n",
    "        rdf = mt.ReadRDF('RDFs/{}bead{}.rdf'.format(i,j), quiet = True)\n",
    "        pot = mt.ReadPot('MagiC_Potentials/{}beadpotential{}.pot'.format(i,j), quiet = True)\n",
    "        rdflist.append(rdf)\n",
    "        potlist.append(pot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.025, 14.975, 300)\n",
    "for i in range(len(x)):\n",
    "    x[i] = round(x[i], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdfs = []\n",
    "for i in range(len(rdflist)):\n",
    "    N = len(rdflist[i].DFs)\n",
    "    holder = np.zeros((465, 300))\n",
    "    for j in range(N):\n",
    "        startindex = np.where(x == round(rdflist[i].DFs[j].x[0], 3))[0][0]\n",
    "        for k in range(300):\n",
    "            if k < startindex:\n",
    "                holder[j][k] = 0\n",
    "            elif k >= startindex and k-startindex < len(rdflist[i].DFs[j].x):\n",
    "                holder[j][k] = rdflist[i].DFs[j].y[k-startindex]\n",
    "            else:\n",
    "                holder[j][k] = 0\n",
    "    rdfs.append(holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "pots = []\n",
    "for i in range(len(rdflist)):\n",
    "    N = len(rdflist[i].DFs)\n",
    "    holder = np.zeros((465, 300))\n",
    "    for j in range(N):\n",
    "        startindex = np.where(x == round(potlist[i].DFs[j].x[0], 3))[0][0]\n",
    "        for k in range(300):\n",
    "            if k < startindex:\n",
    "                holder[j][k] = 60000 - 50*i\n",
    "            elif k >= startindex and k-startindex < len(potlist[i].DFs[j].x):\n",
    "                holder[j][k] = potlist[i].DFs[j].y[k-startindex]\n",
    "            else:\n",
    "                print(\"error\", i, j)\n",
    "    pots.append(holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "pots = tf.stack(pots)\n",
    "rdfs = tf.stack(pots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pots)):\n",
    "    pots[i] = pots[i] + 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-capture",
   "metadata": {},
   "source": [
    "## Building & Training Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "northern-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpe(ytrue, ypred):\n",
    "    loss = tf.keras.losses.mean_absolute_percentage_error(ytrue,ypred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "elect-rochester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "8/8 [==============================] - 6s 770ms/step - loss: 3377588.0000 - val_loss: 2295214.5000\n",
      "Epoch 2/5000\n",
      "8/8 [==============================] - 5s 685ms/step - loss: 2264479.2500 - val_loss: 2257000.7500\n",
      "Epoch 3/5000\n",
      "8/8 [==============================] - 6s 695ms/step - loss: 1803896.2500 - val_loss: 1276509.6250\n",
      "Epoch 4/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 1384154.5000 - val_loss: 454366.0312\n",
      "Epoch 5/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 1050026.7500 - val_loss: 314884.7188\n",
      "Epoch 6/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 977004.0000 - val_loss: 789679.1875\n",
      "Epoch 7/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 926610.9375 - val_loss: 494973.1250\n",
      "Epoch 8/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 892182.5625 - val_loss: 350797.4062\n",
      "Epoch 9/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 820203.9375 - val_loss: 759648.5625\n",
      "Epoch 10/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 962003.9375 - val_loss: 1012093.4375\n",
      "Epoch 11/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 950592.9375 - val_loss: 777897.8750\n",
      "Epoch 12/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 961242.9375 - val_loss: 983688.3750\n",
      "Epoch 13/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 960034.3750 - val_loss: 324257.7812\n",
      "Epoch 14/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 776789.0000 - val_loss: 439088.0625\n",
      "Epoch 15/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 783503.3750 - val_loss: 367907.6562\n",
      "Epoch 16/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 810815.7500 - val_loss: 754816.1875\n",
      "Epoch 17/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 804985.5625 - val_loss: 416643.5312\n",
      "Epoch 18/5000\n",
      "8/8 [==============================] - 6s 769ms/step - loss: 752555.8750 - val_loss: 392141.4688\n",
      "Epoch 19/5000\n",
      "8/8 [==============================] - 6s 810ms/step - loss: 742589.9375 - val_loss: 426895.0000\n",
      "Epoch 20/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 699356.9375 - val_loss: 515296.9375\n",
      "Epoch 21/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 678553.9375 - val_loss: 195972.9375\n",
      "Epoch 22/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 660125.0625 - val_loss: 286379.4062\n",
      "Epoch 23/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 634791.3125 - val_loss: 353250.5312\n",
      "Epoch 24/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 663405.2500 - val_loss: 204690.5156\n",
      "Epoch 25/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 637036.4375 - val_loss: 204057.0781\n",
      "Epoch 26/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 598681.0000 - val_loss: 337134.1875\n",
      "Epoch 27/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 634271.3125 - val_loss: 303281.8125\n",
      "Epoch 28/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 607942.0000 - val_loss: 157282.3281\n",
      "Epoch 29/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 595690.5625 - val_loss: 377726.8438\n",
      "Epoch 30/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 595760.8750 - val_loss: 149843.5625\n",
      "Epoch 31/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 582163.2500 - val_loss: 220329.8281\n",
      "Epoch 32/5000\n",
      "8/8 [==============================] - 7s 906ms/step - loss: 588814.8750 - val_loss: 371599.1250\n",
      "Epoch 33/5000\n",
      "8/8 [==============================] - 7s 885ms/step - loss: 599188.0000 - val_loss: 381157.4688\n",
      "Epoch 34/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 596383.8125 - val_loss: 311257.6562\n",
      "Epoch 35/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 637116.8125 - val_loss: 518315.2812\n",
      "Epoch 36/5000\n",
      "8/8 [==============================] - 8s 944ms/step - loss: 624239.0625 - val_loss: 555760.7500\n",
      "Epoch 37/5000\n",
      "8/8 [==============================] - 7s 884ms/step - loss: 631530.1250 - val_loss: 524505.9375\n",
      "Epoch 38/5000\n",
      "8/8 [==============================] - 7s 907ms/step - loss: 653470.3750 - val_loss: 467931.9375\n",
      "Epoch 39/5000\n",
      "8/8 [==============================] - 7s 892ms/step - loss: 622003.8125 - val_loss: 725598.2500\n",
      "Epoch 40/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 652380.6875 - val_loss: 962981.3125\n",
      "Epoch 41/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 636019.7500 - val_loss: 372784.2812\n",
      "Epoch 42/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 575310.4375 - val_loss: 360323.5938\n",
      "Epoch 43/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 550708.1875 - val_loss: 429652.0000\n",
      "Epoch 44/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 543030.6875 - val_loss: 353771.7812\n",
      "Epoch 45/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 528540.3125 - val_loss: 175412.0938\n",
      "Epoch 46/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 531730.2500 - val_loss: 380813.8750\n",
      "Epoch 47/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 492439.4062 - val_loss: 287969.5000\n",
      "Epoch 48/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 474361.4062 - val_loss: 119787.2266\n",
      "Epoch 49/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 510175.4062 - val_loss: 326000.9688\n",
      "Epoch 50/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 518073.9062 - val_loss: 483677.0625\n",
      "Epoch 51/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 546285.3125 - val_loss: 184943.0156\n",
      "Epoch 52/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 488434.4062 - val_loss: 135366.0469\n",
      "Epoch 53/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 470211.0938 - val_loss: 236302.0938\n",
      "Epoch 54/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 476566.0000 - val_loss: 329736.8125\n",
      "Epoch 55/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 478436.2812 - val_loss: 142531.1562\n",
      "Epoch 56/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 440434.0625 - val_loss: 282779.5312\n",
      "Epoch 57/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 475498.0625 - val_loss: 253283.2188\n",
      "Epoch 58/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 472165.5312 - val_loss: 184255.7969\n",
      "Epoch 59/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 438768.2812 - val_loss: 204302.7188\n",
      "Epoch 60/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 425121.4688 - val_loss: 155005.9375\n",
      "Epoch 61/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 437171.5312 - val_loss: 407067.9062\n",
      "Epoch 62/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 447959.4688 - val_loss: 300296.5312\n",
      "Epoch 63/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 467951.1250 - val_loss: 108679.3828\n",
      "Epoch 64/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 474576.9688 - val_loss: 228654.1406\n",
      "Epoch 65/5000\n",
      "8/8 [==============================] - 7s 894ms/step - loss: 445179.0938 - val_loss: 458612.1250\n",
      "Epoch 66/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 469739.7188 - val_loss: 290068.2812\n",
      "Epoch 67/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 435537.1875 - val_loss: 194030.7031\n",
      "Epoch 68/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 400501.2812 - val_loss: 148590.1406\n",
      "Epoch 69/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 401343.1250 - val_loss: 185073.2031\n",
      "Epoch 70/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 398362.5312 - val_loss: 123753.8359\n",
      "Epoch 71/5000\n",
      "8/8 [==============================] - 7s 937ms/step - loss: 414334.1250 - val_loss: 124170.7969\n",
      "Epoch 72/5000\n",
      "8/8 [==============================] - 7s 856ms/step - loss: 397893.4688 - val_loss: 202023.4062\n",
      "Epoch 73/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 424922.7812 - val_loss: 169372.9688\n",
      "Epoch 74/5000\n",
      "8/8 [==============================] - 7s 819ms/step - loss: 410706.4062 - val_loss: 166763.5156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 372595.2812 - val_loss: 182516.9844\n",
      "Epoch 76/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 378383.9062 - val_loss: 186612.6719\n",
      "Epoch 77/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 391234.6562 - val_loss: 202107.3594\n",
      "Epoch 78/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 398089.9062 - val_loss: 163331.0000\n",
      "Epoch 79/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 380767.4688 - val_loss: 112931.4922\n",
      "Epoch 80/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 373587.5312 - val_loss: 97549.7344\n",
      "Epoch 81/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 383827.5938 - val_loss: 91539.8516\n",
      "Epoch 82/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 368718.9688 - val_loss: 108376.7344\n",
      "Epoch 83/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 377962.6875 - val_loss: 109954.3516\n",
      "Epoch 84/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 364461.8750 - val_loss: 89463.9531\n",
      "Epoch 85/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 356049.8438 - val_loss: 84967.6172\n",
      "Epoch 86/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 341740.6875 - val_loss: 81416.3203\n",
      "Epoch 87/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 343246.4062 - val_loss: 80130.5156\n",
      "Epoch 88/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 341022.0000 - val_loss: 80866.9453\n",
      "Epoch 89/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 327772.8438 - val_loss: 94389.4219\n",
      "Epoch 90/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 320747.0625 - val_loss: 89665.0703\n",
      "Epoch 91/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 338504.4375 - val_loss: 78509.8672\n",
      "Epoch 92/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 340808.5312 - val_loss: 73383.2422\n",
      "Epoch 93/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 324786.1875 - val_loss: 77934.3203\n",
      "Epoch 94/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 337455.8438 - val_loss: 74051.2656\n",
      "Epoch 95/5000\n",
      "8/8 [==============================] - 6s 771ms/step - loss: 329231.9375 - val_loss: 74692.0312\n",
      "Epoch 96/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 322359.0938 - val_loss: 69953.5859\n",
      "Epoch 97/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 312193.6562 - val_loss: 66862.3438\n",
      "Epoch 98/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 308125.3438 - val_loss: 69577.2891\n",
      "Epoch 99/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 315013.7188 - val_loss: 77905.0391\n",
      "Epoch 100/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 320904.3438 - val_loss: 74048.9766\n",
      "Epoch 101/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 309991.8125 - val_loss: 66691.1406\n",
      "Epoch 102/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 305672.6875 - val_loss: 66773.7500\n",
      "Epoch 103/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 313193.6562 - val_loss: 69678.9062\n",
      "Epoch 104/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 308219.8750 - val_loss: 69019.7578\n",
      "Epoch 105/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 312627.3125 - val_loss: 68286.4062\n",
      "Epoch 106/5000\n",
      "8/8 [==============================] - 7s 815ms/step - loss: 301991.4375 - val_loss: 63177.2422\n",
      "Epoch 107/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 313923.9688 - val_loss: 69951.6094\n",
      "Epoch 108/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 307385.1875 - val_loss: 66875.1719\n",
      "Epoch 109/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 294654.5000 - val_loss: 59898.1602\n",
      "Epoch 110/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 295156.5000 - val_loss: 60915.4336\n",
      "Epoch 111/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 303658.8125 - val_loss: 71797.7578\n",
      "Epoch 112/5000\n",
      "8/8 [==============================] - 6s 770ms/step - loss: 306266.1250 - val_loss: 67712.9375\n",
      "Epoch 113/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 303795.9375 - val_loss: 66517.1562\n",
      "Epoch 114/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 297935.6875 - val_loss: 63815.0000\n",
      "Epoch 115/5000\n",
      "8/8 [==============================] - 7s 840ms/step - loss: 295218.0312 - val_loss: 60834.3164\n",
      "Epoch 116/5000\n",
      "8/8 [==============================] - 6s 809ms/step - loss: 288934.4688 - val_loss: 59697.4258\n",
      "Epoch 117/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 290338.5625 - val_loss: 66583.9531\n",
      "Epoch 118/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 302011.9375 - val_loss: 61951.3359\n",
      "Epoch 119/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 281664.0625 - val_loss: 60212.4414\n",
      "Epoch 120/5000\n",
      "8/8 [==============================] - 7s 823ms/step - loss: 283147.0938 - val_loss: 59194.0078\n",
      "Epoch 121/5000\n",
      "8/8 [==============================] - 6s 809ms/step - loss: 288203.0312 - val_loss: 63048.3711\n",
      "Epoch 122/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 279748.4062 - val_loss: 59214.6484\n",
      "Epoch 123/5000\n",
      "8/8 [==============================] - 7s 820ms/step - loss: 262766.8438 - val_loss: 57327.7383\n",
      "Epoch 124/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 266309.4688 - val_loss: 58994.9141\n",
      "Epoch 125/5000\n",
      "8/8 [==============================] - 7s 833ms/step - loss: 282766.7812 - val_loss: 62982.6016\n",
      "Epoch 126/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 287477.9062 - val_loss: 58938.5820\n",
      "Epoch 127/5000\n",
      "8/8 [==============================] - 7s 814ms/step - loss: 292544.5938 - val_loss: 61725.4102\n",
      "Epoch 128/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 279541.3750 - val_loss: 64773.4844\n",
      "Epoch 129/5000\n",
      "8/8 [==============================] - 7s 821ms/step - loss: 279703.7812 - val_loss: 61109.1836\n",
      "Epoch 130/5000\n",
      "8/8 [==============================] - 7s 816ms/step - loss: 276745.8438 - val_loss: 60249.1875\n",
      "Epoch 131/5000\n",
      "8/8 [==============================] - 7s 828ms/step - loss: 271571.2188 - val_loss: 57254.1484\n",
      "Epoch 132/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 275550.2500 - val_loss: 55697.0664\n",
      "Epoch 133/5000\n",
      "8/8 [==============================] - 7s 911ms/step - loss: 264106.4375 - val_loss: 55862.0664\n",
      "Epoch 134/5000\n",
      "8/8 [==============================] - 7s 859ms/step - loss: 256976.5156 - val_loss: 57487.4297\n",
      "Epoch 135/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 260256.9531 - val_loss: 54369.4414\n",
      "Epoch 136/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 248165.0781 - val_loss: 53260.4297\n",
      "Epoch 137/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 250566.3281 - val_loss: 52416.6680\n",
      "Epoch 138/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 258429.2031 - val_loss: 57506.4648\n",
      "Epoch 139/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 266453.6562 - val_loss: 55309.8047\n",
      "Epoch 140/5000\n",
      "8/8 [==============================] - 6s 809ms/step - loss: 254504.0938 - val_loss: 59012.8398\n",
      "Epoch 141/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 262357.3438 - val_loss: 56129.7930\n",
      "Epoch 142/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 251717.5000 - val_loss: 54218.0547\n",
      "Epoch 143/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 255125.5469 - val_loss: 52776.7852\n",
      "Epoch 144/5000\n",
      "8/8 [==============================] - 6s 810ms/step - loss: 247512.2656 - val_loss: 52106.6094\n",
      "Epoch 145/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 248764.2656 - val_loss: 56184.1094\n",
      "Epoch 146/5000\n",
      "8/8 [==============================] - 7s 836ms/step - loss: 250559.3594 - val_loss: 52499.7031\n",
      "Epoch 147/5000\n",
      "8/8 [==============================] - 7s 822ms/step - loss: 243551.1406 - val_loss: 51153.6758\n",
      "Epoch 148/5000\n",
      "8/8 [==============================] - 7s 831ms/step - loss: 239639.1719 - val_loss: 50356.6094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 244218.0625 - val_loss: 56859.3203\n",
      "Epoch 150/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 242848.9844 - val_loss: 52713.5664\n",
      "Epoch 151/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 254063.8281 - val_loss: 52949.8203\n",
      "Epoch 152/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 241378.3594 - val_loss: 50618.8594\n",
      "Epoch 153/5000\n",
      "8/8 [==============================] - 7s 815ms/step - loss: 245282.3281 - val_loss: 54768.7305\n",
      "Epoch 154/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 241784.1094 - val_loss: 53926.5391\n",
      "Epoch 155/5000\n",
      "8/8 [==============================] - 6s 809ms/step - loss: 245349.2500 - val_loss: 53332.9141\n",
      "Epoch 156/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 252665.3281 - val_loss: 52397.3008\n",
      "Epoch 157/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 249085.8594 - val_loss: 54922.1406\n",
      "Epoch 158/5000\n",
      "8/8 [==============================] - 7s 814ms/step - loss: 251534.2344 - val_loss: 50494.2266\n",
      "Epoch 159/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 238704.3281 - val_loss: 49050.3945\n",
      "Epoch 160/5000\n",
      "8/8 [==============================] - 7s 821ms/step - loss: 241215.7344 - val_loss: 52687.4297\n",
      "Epoch 161/5000\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 237190.4688 - val_loss: 51372.7344\n",
      "Epoch 162/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 242078.5469 - val_loss: 49310.2930\n",
      "Epoch 163/5000\n",
      "8/8 [==============================] - 7s 829ms/step - loss: 246471.3281 - val_loss: 49246.5234\n",
      "Epoch 164/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 227517.2344 - val_loss: 47944.3281\n",
      "Epoch 165/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 229483.5156 - val_loss: 47856.7734\n",
      "Epoch 166/5000\n",
      "8/8 [==============================] - 7s 817ms/step - loss: 231956.2812 - val_loss: 48813.7383\n",
      "Epoch 167/5000\n",
      "8/8 [==============================] - 7s 813ms/step - loss: 227152.9844 - val_loss: 48096.4961\n",
      "Epoch 168/5000\n",
      "8/8 [==============================] - 7s 813ms/step - loss: 220741.5781 - val_loss: 44714.4453\n",
      "Epoch 169/5000\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 214022.7969 - val_loss: 48875.5977\n",
      "Epoch 170/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 228654.2031 - val_loss: 52412.8594\n",
      "Epoch 171/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 242289.9688 - val_loss: 51182.7500\n",
      "Epoch 172/5000\n",
      "8/8 [==============================] - 7s 819ms/step - loss: 226564.0000 - val_loss: 50840.8125\n",
      "Epoch 173/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 229606.3125 - val_loss: 52921.2852\n",
      "Epoch 174/5000\n",
      "8/8 [==============================] - 7s 903ms/step - loss: 239078.7656 - val_loss: 50901.2109\n",
      "Epoch 175/5000\n",
      "8/8 [==============================] - 7s 853ms/step - loss: 234204.4531 - val_loss: 46466.7852\n",
      "Epoch 176/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 216738.3438 - val_loss: 48343.6484\n",
      "Epoch 177/5000\n",
      "8/8 [==============================] - 7s 822ms/step - loss: 219221.9531 - val_loss: 46393.7656\n",
      "Epoch 178/5000\n",
      "8/8 [==============================] - 7s 816ms/step - loss: 220460.1875 - val_loss: 46958.1797\n",
      "Epoch 179/5000\n",
      "8/8 [==============================] - 7s 824ms/step - loss: 215475.9375 - val_loss: 47351.4219\n",
      "Epoch 180/5000\n",
      "8/8 [==============================] - 7s 819ms/step - loss: 231976.3594 - val_loss: 53391.3984\n",
      "Epoch 181/5000\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 225578.5312 - val_loss: 48242.6055\n",
      "Epoch 182/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 226132.9844 - val_loss: 45766.3203\n",
      "Epoch 183/5000\n",
      "8/8 [==============================] - 7s 827ms/step - loss: 215952.9531 - val_loss: 47513.4531\n",
      "Epoch 184/5000\n",
      "8/8 [==============================] - 6s 809ms/step - loss: 220165.0312 - val_loss: 49229.6016\n",
      "Epoch 185/5000\n",
      "8/8 [==============================] - 7s 823ms/step - loss: 213948.2344 - val_loss: 44022.7891\n",
      "Epoch 186/5000\n",
      "8/8 [==============================] - 7s 817ms/step - loss: 222183.1094 - val_loss: 50687.3555\n",
      "Epoch 187/5000\n",
      "8/8 [==============================] - 7s 825ms/step - loss: 218868.1094 - val_loss: 46560.3984\n",
      "Epoch 188/5000\n",
      "8/8 [==============================] - 7s 830ms/step - loss: 223544.7500 - val_loss: 45550.7500\n",
      "Epoch 189/5000\n",
      "8/8 [==============================] - 7s 814ms/step - loss: 225407.2031 - val_loss: 50368.6406\n",
      "Epoch 190/5000\n",
      "8/8 [==============================] - 7s 817ms/step - loss: 222830.8594 - val_loss: 43571.8633\n",
      "Epoch 191/5000\n",
      "8/8 [==============================] - 7s 822ms/step - loss: 214152.3125 - val_loss: 46359.1602\n",
      "Epoch 192/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 214062.1562 - val_loss: 45401.1133\n",
      "Epoch 193/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 204926.0938 - val_loss: 43744.8789\n",
      "Epoch 194/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 205705.7500 - val_loss: 46141.6719\n",
      "Epoch 195/5000\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 210154.5781 - val_loss: 47227.3398\n",
      "Epoch 196/5000\n",
      "8/8 [==============================] - 7s 920ms/step - loss: 210087.8906 - val_loss: 42074.4102\n",
      "Epoch 197/5000\n",
      "8/8 [==============================] - 7s 840ms/step - loss: 207790.7969 - val_loss: 42351.0508\n",
      "Epoch 198/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 209105.2969 - val_loss: 46268.3047\n",
      "Epoch 199/5000\n",
      "8/8 [==============================] - 7s 817ms/step - loss: 211180.7969 - val_loss: 48268.3906\n",
      "Epoch 200/5000\n",
      "8/8 [==============================] - 6s 809ms/step - loss: 218506.1875 - val_loss: 44255.1055\n",
      "Epoch 201/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 209362.2656 - val_loss: 46238.2148\n",
      "Epoch 202/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 208767.1562 - val_loss: 45426.9531\n",
      "Epoch 203/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 202463.9844 - val_loss: 46374.1602\n",
      "Epoch 204/5000\n",
      "8/8 [==============================] - 7s 820ms/step - loss: 212177.5000 - val_loss: 44629.0352\n",
      "Epoch 205/5000\n",
      "8/8 [==============================] - 7s 813ms/step - loss: 204180.4375 - val_loss: 48543.0547\n",
      "Epoch 206/5000\n",
      "8/8 [==============================] - 7s 819ms/step - loss: 213515.3125 - val_loss: 44146.2500\n",
      "Epoch 207/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 199028.7812 - val_loss: 44041.7773\n",
      "Epoch 208/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 193904.0781 - val_loss: 43853.9844\n",
      "Epoch 209/5000\n",
      "8/8 [==============================] - 6s 809ms/step - loss: 205502.7344 - val_loss: 54075.0000\n",
      "Epoch 210/5000\n",
      "8/8 [==============================] - 6s 810ms/step - loss: 216206.3438 - val_loss: 55025.2734\n",
      "Epoch 211/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 234975.4844 - val_loss: 126064.3828\n",
      "Epoch 212/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 245944.5000 - val_loss: 320468.3750\n",
      "Epoch 213/5000\n",
      "8/8 [==============================] - 7s 813ms/step - loss: 256443.4844 - val_loss: 115462.5547\n",
      "Epoch 214/5000\n",
      "8/8 [==============================] - 7s 813ms/step - loss: 219636.3125 - val_loss: 101935.5859\n",
      "Epoch 215/5000\n",
      "8/8 [==============================] - 7s 815ms/step - loss: 219605.3281 - val_loss: 100183.7500\n",
      "Epoch 216/5000\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 210095.5000 - val_loss: 90359.0156\n",
      "Epoch 217/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 206598.9375 - val_loss: 70291.5391\n",
      "Epoch 218/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 213677.7344 - val_loss: 146922.1719\n",
      "Epoch 219/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 211439.1719 - val_loss: 96172.7344\n",
      "Epoch 220/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 210805.3281 - val_loss: 114126.4688\n",
      "Epoch 221/5000\n",
      "8/8 [==============================] - 7s 825ms/step - loss: 208770.7188 - val_loss: 87493.2422\n",
      "Epoch 222/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 213932.9375 - val_loss: 81260.8828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 200857.4219 - val_loss: 64358.3594\n",
      "Epoch 224/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 198608.0000 - val_loss: 52414.4609\n",
      "Epoch 225/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 203393.4531 - val_loss: 55090.8477\n",
      "Epoch 226/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 211782.2969 - val_loss: 48201.0664\n",
      "Epoch 227/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 210898.6875 - val_loss: 48252.6484\n",
      "Epoch 228/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 203028.7031 - val_loss: 60074.7891\n",
      "Epoch 229/5000\n",
      "8/8 [==============================] - 7s 813ms/step - loss: 196296.4062 - val_loss: 49690.7070\n",
      "Epoch 230/5000\n",
      "8/8 [==============================] - 7s 821ms/step - loss: 195145.0625 - val_loss: 44691.0234\n",
      "Epoch 231/5000\n",
      "8/8 [==============================] - 7s 816ms/step - loss: 201419.9844 - val_loss: 52929.0156\n",
      "Epoch 232/5000\n",
      "8/8 [==============================] - 7s 817ms/step - loss: 196023.5938 - val_loss: 47065.3828\n",
      "Epoch 233/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 191625.5312 - val_loss: 48783.2734\n",
      "Epoch 234/5000\n",
      "8/8 [==============================] - 7s 894ms/step - loss: 195944.7969 - val_loss: 41515.6016\n",
      "Epoch 235/5000\n",
      "8/8 [==============================] - 7s 859ms/step - loss: 190393.8594 - val_loss: 40674.5898\n",
      "Epoch 236/5000\n",
      "8/8 [==============================] - 7s 814ms/step - loss: 190846.5000 - val_loss: 44605.0820\n",
      "Epoch 237/5000\n",
      "8/8 [==============================] - 7s 824ms/step - loss: 196492.3438 - val_loss: 40366.5234\n",
      "Epoch 238/5000\n",
      "8/8 [==============================] - 7s 814ms/step - loss: 190362.4219 - val_loss: 41234.8164\n",
      "Epoch 239/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 188896.7031 - val_loss: 40194.5234\n",
      "Epoch 240/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 183521.1875 - val_loss: 38893.6250\n",
      "Epoch 241/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 186681.7969 - val_loss: 38479.7305\n",
      "Epoch 242/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 188901.3906 - val_loss: 38973.5508\n",
      "Epoch 243/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 187335.9219 - val_loss: 39948.6016\n",
      "Epoch 244/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 184794.0000 - val_loss: 40666.9180\n",
      "Epoch 245/5000\n",
      "8/8 [==============================] - 7s 823ms/step - loss: 177969.1719 - val_loss: 37325.6094\n",
      "Epoch 246/5000\n",
      "8/8 [==============================] - 8s 1s/step - loss: 185616.4688 - val_loss: 39455.9375\n",
      "Epoch 247/5000\n",
      "8/8 [==============================] - 7s 858ms/step - loss: 174759.7031 - val_loss: 36517.4805\n",
      "Epoch 248/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 174855.2812 - val_loss: 38841.0078\n",
      "Epoch 249/5000\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 182636.2344 - val_loss: 38181.8320\n",
      "Epoch 250/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 180244.2500 - val_loss: 36406.1094\n",
      "Epoch 251/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 176146.1875 - val_loss: 36525.7617\n",
      "Epoch 252/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 172708.3281 - val_loss: 37126.0469\n",
      "Epoch 253/5000\n",
      "8/8 [==============================] - 7s 871ms/step - loss: 169724.2344 - val_loss: 34874.7383\n",
      "Epoch 254/5000\n",
      "8/8 [==============================] - 7s 827ms/step - loss: 170819.2969 - val_loss: 39203.0352\n",
      "Epoch 255/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 184485.4062 - val_loss: 39009.8672\n",
      "Epoch 256/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 176277.2500 - val_loss: 38433.2695\n",
      "Epoch 257/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 181459.4219 - val_loss: 39796.1758\n",
      "Epoch 258/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 173316.7656 - val_loss: 36568.3867\n",
      "Epoch 259/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 182631.1562 - val_loss: 36909.5898\n",
      "Epoch 260/5000\n",
      "8/8 [==============================] - 7s 854ms/step - loss: 180840.7500 - val_loss: 38326.5352\n",
      "Epoch 261/5000\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 176303.2188 - val_loss: 35796.4922\n",
      "Epoch 262/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 177117.8906 - val_loss: 37170.0234\n",
      "Epoch 263/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 173013.1406 - val_loss: 38023.4648\n",
      "Epoch 264/5000\n",
      "8/8 [==============================] - 7s 862ms/step - loss: 173192.2188 - val_loss: 36379.4492\n",
      "Epoch 265/5000\n",
      "8/8 [==============================] - 7s 816ms/step - loss: 178869.2188 - val_loss: 37646.3711\n",
      "Epoch 266/5000\n",
      "8/8 [==============================] - 7s 831ms/step - loss: 175524.7656 - val_loss: 36715.8594\n",
      "Epoch 267/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 177301.0312 - val_loss: 37491.8906\n",
      "Epoch 268/5000\n",
      "8/8 [==============================] - 7s 860ms/step - loss: 169877.5781 - val_loss: 34218.7891\n",
      "Epoch 269/5000\n",
      "8/8 [==============================] - 6s 809ms/step - loss: 170464.3906 - val_loss: 37792.3086\n",
      "Epoch 270/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 176045.2969 - val_loss: 37414.7344\n",
      "Epoch 271/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 171258.9062 - val_loss: 39762.2500\n",
      "Epoch 272/5000\n",
      "8/8 [==============================] - 7s 821ms/step - loss: 171342.2344 - val_loss: 38243.9297\n",
      "Epoch 273/5000\n",
      "8/8 [==============================] - 7s 928ms/step - loss: 172385.8125 - val_loss: 39550.1758\n",
      "Epoch 274/5000\n",
      "8/8 [==============================] - 8s 995ms/step - loss: 176627.3906 - val_loss: 37587.9961\n",
      "Epoch 275/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 174300.5625 - val_loss: 36918.8477\n",
      "Epoch 276/5000\n",
      "8/8 [==============================] - 7s 848ms/step - loss: 179599.2656 - val_loss: 37463.8398\n",
      "Epoch 277/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 174484.3281 - val_loss: 36928.1211\n",
      "Epoch 278/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 172121.6719 - val_loss: 38409.2617\n",
      "Epoch 279/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 177160.2344 - val_loss: 38555.6250\n",
      "Epoch 280/5000\n",
      "8/8 [==============================] - 7s 850ms/step - loss: 176562.7656 - val_loss: 35359.6445\n",
      "Epoch 281/5000\n",
      "8/8 [==============================] - 6s 809ms/step - loss: 173397.2500 - val_loss: 41339.4453\n",
      "Epoch 282/5000\n",
      "8/8 [==============================] - 7s 837ms/step - loss: 176781.2500 - val_loss: 37650.1289\n",
      "Epoch 283/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 180969.2344 - val_loss: 35982.0977\n",
      "Epoch 284/5000\n",
      "8/8 [==============================] - 7s 856ms/step - loss: 179188.7500 - val_loss: 39147.5430\n",
      "Epoch 285/5000\n",
      "8/8 [==============================] - 7s 824ms/step - loss: 174802.2344 - val_loss: 36094.7617\n",
      "Epoch 286/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 168574.0625 - val_loss: 39015.2227\n",
      "Epoch 287/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 165474.3438 - val_loss: 34936.5781\n",
      "Epoch 288/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 165683.3281 - val_loss: 36027.8164\n",
      "Epoch 289/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 171136.3281 - val_loss: 35482.8906\n",
      "Epoch 290/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 167731.3438 - val_loss: 34856.6055\n",
      "Epoch 291/5000\n",
      "8/8 [==============================] - 7s 860ms/step - loss: 169067.5625 - val_loss: 37348.9492\n",
      "Epoch 292/5000\n",
      "8/8 [==============================] - 7s 816ms/step - loss: 173450.5625 - val_loss: 34501.3125\n",
      "Epoch 293/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 167793.6719 - val_loss: 38871.2695\n",
      "Epoch 294/5000\n",
      "8/8 [==============================] - 7s 856ms/step - loss: 168758.2969 - val_loss: 36698.8477\n",
      "Epoch 295/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 170837.7656 - val_loss: 37572.6914\n",
      "Epoch 296/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 169175.5000 - val_loss: 36866.0820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/5000\n",
      "8/8 [==============================] - 6s 771ms/step - loss: 165611.5000 - val_loss: 32589.8828\n",
      "Epoch 298/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 166806.4844 - val_loss: 33227.2383\n",
      "Epoch 299/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 167076.1875 - val_loss: 35690.8984\n",
      "Epoch 300/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 170728.1562 - val_loss: 36064.4609\n",
      "Epoch 301/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 166278.5469 - val_loss: 36075.8594\n",
      "Epoch 302/5000\n",
      "8/8 [==============================] - 7s 854ms/step - loss: 166020.5156 - val_loss: 35002.1836\n",
      "Epoch 303/5000\n",
      "8/8 [==============================] - 7s 819ms/step - loss: 160605.4375 - val_loss: 33151.6953\n",
      "Epoch 304/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 154152.8594 - val_loss: 33437.1602\n",
      "Epoch 305/5000\n",
      "8/8 [==============================] - 6s 771ms/step - loss: 161617.5781 - val_loss: 34601.8477\n",
      "Epoch 306/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 162289.3438 - val_loss: 33848.7070\n",
      "Epoch 307/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 162166.6875 - val_loss: 35746.1523\n",
      "Epoch 308/5000\n",
      "8/8 [==============================] - 7s 880ms/step - loss: 159032.7812 - val_loss: 38438.7148\n",
      "Epoch 309/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 170024.5000 - val_loss: 35179.6484\n",
      "Epoch 310/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 164842.4531 - val_loss: 41212.4570\n",
      "Epoch 311/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 168220.0156 - val_loss: 41215.0000\n",
      "Epoch 312/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 163374.7500 - val_loss: 43444.3398\n",
      "Epoch 313/5000\n",
      "8/8 [==============================] - 7s 885ms/step - loss: 163020.7344 - val_loss: 38562.9727\n",
      "Epoch 314/5000\n",
      "8/8 [==============================] - 7s 848ms/step - loss: 156741.9219 - val_loss: 37877.8594\n",
      "Epoch 315/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 159226.9688 - val_loss: 75292.0156\n",
      "Epoch 316/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 156401.2500 - val_loss: 41759.9414\n",
      "Epoch 317/5000\n",
      "8/8 [==============================] - 7s 895ms/step - loss: 164582.0469 - val_loss: 56358.2500\n",
      "Epoch 318/5000\n",
      "8/8 [==============================] - 7s 854ms/step - loss: 166480.6406 - val_loss: 62835.1797\n",
      "Epoch 319/5000\n",
      "8/8 [==============================] - 7s 900ms/step - loss: 162487.5938 - val_loss: 40065.5273\n",
      "Epoch 320/5000\n",
      "8/8 [==============================] - 7s 841ms/step - loss: 164616.8281 - val_loss: 45874.7031\n",
      "Epoch 321/5000\n",
      "8/8 [==============================] - 7s 836ms/step - loss: 161285.4688 - val_loss: 52202.8477\n",
      "Epoch 322/5000\n",
      "8/8 [==============================] - 7s 835ms/step - loss: 160669.4219 - val_loss: 41273.3984\n",
      "Epoch 323/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 163778.4219 - val_loss: 48575.6602\n",
      "Epoch 324/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 163327.6562 - val_loss: 43655.8906\n",
      "Epoch 325/5000\n",
      "8/8 [==============================] - 7s 895ms/step - loss: 166367.9219 - val_loss: 43939.0117\n",
      "Epoch 326/5000\n",
      "8/8 [==============================] - 7s 830ms/step - loss: 163856.8281 - val_loss: 46630.7148\n",
      "Epoch 327/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 166004.5625 - val_loss: 40563.2148\n",
      "Epoch 328/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 166361.5312 - val_loss: 52256.9141\n",
      "Epoch 329/5000\n",
      "8/8 [==============================] - 7s 893ms/step - loss: 163565.7188 - val_loss: 41292.5234\n",
      "Epoch 330/5000\n",
      "8/8 [==============================] - 7s 838ms/step - loss: 160582.3125 - val_loss: 40478.7930\n",
      "Epoch 331/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 161303.6406 - val_loss: 45212.0273\n",
      "Epoch 332/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 168408.9688 - val_loss: 41158.2656\n",
      "Epoch 333/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 154767.5312 - val_loss: 34509.7461\n",
      "Epoch 334/5000\n",
      "8/8 [==============================] - 6s 769ms/step - loss: 156749.0938 - val_loss: 38552.3008\n",
      "Epoch 335/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 161092.4219 - val_loss: 34969.5078\n",
      "Epoch 336/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 163940.0469 - val_loss: 50192.0820\n",
      "Epoch 337/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 159784.4062 - val_loss: 39970.5078\n",
      "Epoch 338/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 161312.7344 - val_loss: 41199.9023\n",
      "Epoch 339/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 158518.4844 - val_loss: 41680.1523\n",
      "Epoch 340/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 158676.6094 - val_loss: 38567.5859\n",
      "Epoch 341/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 155866.0156 - val_loss: 35548.9922\n",
      "Epoch 342/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 158333.4844 - val_loss: 35105.8242\n",
      "Epoch 343/5000\n",
      "8/8 [==============================] - 7s 911ms/step - loss: 157616.5625 - val_loss: 37151.4961\n",
      "Epoch 344/5000\n",
      "8/8 [==============================] - 7s 829ms/step - loss: 157787.9688 - val_loss: 34393.5820\n",
      "Epoch 345/5000\n",
      "8/8 [==============================] - 7s 817ms/step - loss: 161310.4062 - val_loss: 33793.1602\n",
      "Epoch 346/5000\n",
      "8/8 [==============================] - 7s 910ms/step - loss: 155175.8125 - val_loss: 37384.5859\n",
      "Epoch 347/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 154795.3594 - val_loss: 41363.1602\n",
      "Epoch 348/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 156957.1406 - val_loss: 39375.5430\n",
      "Epoch 349/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 167245.9375 - val_loss: 37571.6133\n",
      "Epoch 350/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 160620.9219 - val_loss: 34291.5625\n",
      "Epoch 351/5000\n",
      "8/8 [==============================] - 7s 885ms/step - loss: 156780.9531 - val_loss: 33721.3789\n",
      "Epoch 352/5000\n",
      "8/8 [==============================] - 7s 827ms/step - loss: 153899.2344 - val_loss: 32187.7188\n",
      "Epoch 353/5000\n",
      "8/8 [==============================] - 6s 769ms/step - loss: 163859.5781 - val_loss: 32911.3672\n",
      "Epoch 354/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 157524.0000 - val_loss: 31951.4492\n",
      "Epoch 355/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 153055.0000 - val_loss: 31711.0840\n",
      "Epoch 356/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 147661.8438 - val_loss: 36959.8750\n",
      "Epoch 357/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 152749.6094 - val_loss: 31876.8535\n",
      "Epoch 358/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 147096.0312 - val_loss: 36450.8594\n",
      "Epoch 359/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 154525.0781 - val_loss: 33706.1250\n",
      "Epoch 360/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 159260.1406 - val_loss: 37304.1992\n",
      "Epoch 361/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 156616.5156 - val_loss: 38137.9766\n",
      "Epoch 362/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 153953.2344 - val_loss: 49935.3906\n",
      "Epoch 363/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 163580.4844 - val_loss: 178192.5312\n",
      "Epoch 364/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 173956.1562 - val_loss: 300048.2812\n",
      "Epoch 365/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 216179.4062 - val_loss: 97795.3203\n",
      "Epoch 366/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 197706.4062 - val_loss: 118766.8516\n",
      "Epoch 367/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 182142.4844 - val_loss: 149971.6875\n",
      "Epoch 368/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 197230.5312 - val_loss: 179191.1406\n",
      "Epoch 369/5000\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 178071.5000 - val_loss: 73689.5469\n",
      "Epoch 370/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 172923.0469 - val_loss: 96071.5859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 172550.3906 - val_loss: 85242.4297\n",
      "Epoch 372/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 172173.7500 - val_loss: 107096.1328\n",
      "Epoch 373/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 177409.2500 - val_loss: 105079.4531\n",
      "Epoch 374/5000\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 173617.2344 - val_loss: 98362.0781\n",
      "Epoch 375/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 174862.3438 - val_loss: 77695.6797\n",
      "Epoch 376/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 166121.9844 - val_loss: 66615.5078\n",
      "Epoch 377/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 164863.7344 - val_loss: 49198.9531\n",
      "Epoch 378/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 155980.3281 - val_loss: 40859.0195\n",
      "Epoch 379/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 158201.8906 - val_loss: 42775.8828\n",
      "Epoch 380/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 159013.9688 - val_loss: 42776.1172\n",
      "Epoch 381/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 159847.8281 - val_loss: 36529.8867\n",
      "Epoch 382/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 154785.5469 - val_loss: 36432.1250\n",
      "Epoch 383/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 155670.5312 - val_loss: 55489.7617\n",
      "Epoch 384/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 154100.9688 - val_loss: 49901.5820\n",
      "Epoch 385/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 158510.7656 - val_loss: 41985.0391\n",
      "Epoch 386/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 149884.4062 - val_loss: 36516.5742\n",
      "Epoch 387/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 150361.8594 - val_loss: 36698.3828\n",
      "Epoch 388/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 152103.5312 - val_loss: 39370.5859\n",
      "Epoch 389/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 153898.8906 - val_loss: 38364.6914\n",
      "Epoch 390/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 146562.2500 - val_loss: 35830.3750\n",
      "Epoch 391/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 149320.6719 - val_loss: 35749.2461\n",
      "Epoch 392/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 150586.6562 - val_loss: 36739.6016\n",
      "Epoch 393/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 151665.2344 - val_loss: 33053.8672\n",
      "Epoch 394/5000\n",
      "8/8 [==============================] - 7s 813ms/step - loss: 148715.0625 - val_loss: 35266.3203\n",
      "Epoch 395/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 151178.5625 - val_loss: 35430.2773\n",
      "Epoch 396/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 148961.5000 - val_loss: 32837.2695\n",
      "Epoch 397/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 151980.6719 - val_loss: 30927.6836\n",
      "Epoch 398/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 150402.0625 - val_loss: 31790.6992\n",
      "Epoch 399/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 149254.4844 - val_loss: 33689.2617\n",
      "Epoch 400/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 151480.9219 - val_loss: 31112.8125\n",
      "Epoch 401/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 147483.9062 - val_loss: 34584.1523\n",
      "Epoch 402/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 154454.3594 - val_loss: 33785.0156\n",
      "Epoch 403/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 151177.0156 - val_loss: 31407.7754\n",
      "Epoch 404/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 145598.8594 - val_loss: 31053.5273\n",
      "Epoch 405/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 147310.7344 - val_loss: 34989.0195\n",
      "Epoch 406/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 153625.7969 - val_loss: 33423.9922\n",
      "Epoch 407/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 144761.7031 - val_loss: 31000.5000\n",
      "Epoch 408/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 146019.5938 - val_loss: 30507.9609\n",
      "Epoch 409/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 148415.8438 - val_loss: 30357.4160\n",
      "Epoch 410/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 144896.6719 - val_loss: 33159.3242\n",
      "Epoch 411/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 145295.4062 - val_loss: 31428.6074\n",
      "Epoch 412/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 148845.9688 - val_loss: 31067.0977\n",
      "Epoch 413/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 149326.1562 - val_loss: 31137.1172\n",
      "Epoch 414/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 143418.6562 - val_loss: 32151.6035\n",
      "Epoch 415/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 149152.3438 - val_loss: 33405.3281\n",
      "Epoch 416/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 147980.9688 - val_loss: 30434.1660\n",
      "Epoch 417/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 150570.3281 - val_loss: 32449.9961\n",
      "Epoch 418/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 145314.9688 - val_loss: 31060.2559\n",
      "Epoch 419/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 149134.1094 - val_loss: 34455.2266\n",
      "Epoch 420/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 148200.4219 - val_loss: 31500.3477\n",
      "Epoch 421/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 147204.3594 - val_loss: 33102.6133\n",
      "Epoch 422/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 150145.0625 - val_loss: 32429.9570\n",
      "Epoch 423/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 147407.9844 - val_loss: 31800.3711\n",
      "Epoch 424/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 142553.9375 - val_loss: 31615.6836\n",
      "Epoch 425/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 150633.0938 - val_loss: 33009.8086\n",
      "Epoch 426/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 145826.9844 - val_loss: 29436.0078\n",
      "Epoch 427/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 139651.4531 - val_loss: 30239.1250\n",
      "Epoch 428/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 146777.7969 - val_loss: 30263.2461\n",
      "Epoch 429/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 140072.8281 - val_loss: 29971.0664\n",
      "Epoch 430/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 148218.4062 - val_loss: 30444.8457\n",
      "Epoch 431/5000\n",
      "8/8 [==============================] - 7s 877ms/step - loss: 144767.1719 - val_loss: 30959.7168\n",
      "Epoch 432/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 150685.2500 - val_loss: 32547.3047\n",
      "Epoch 433/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 152021.4844 - val_loss: 29998.8828\n",
      "Epoch 434/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 143125.9219 - val_loss: 29912.5547\n",
      "Epoch 435/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 141452.3281 - val_loss: 28379.7285\n",
      "Epoch 436/5000\n",
      "8/8 [==============================] - 7s 813ms/step - loss: 145282.2188 - val_loss: 34782.6484\n",
      "Epoch 437/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 146152.2031 - val_loss: 31502.7520\n",
      "Epoch 438/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 147848.0000 - val_loss: 28583.3379\n",
      "Epoch 439/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 144045.5312 - val_loss: 33081.4805\n",
      "Epoch 440/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 146993.9688 - val_loss: 32432.7891\n",
      "Epoch 441/5000\n",
      "8/8 [==============================] - 6s 809ms/step - loss: 137564.2812 - val_loss: 28827.4707\n",
      "Epoch 442/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 137968.9531 - val_loss: 31187.2324\n",
      "Epoch 443/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 150043.3594 - val_loss: 32419.9062\n",
      "Epoch 444/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 143948.9375 - val_loss: 31378.8945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/5000\n",
      "8/8 [==============================] - 7s 895ms/step - loss: 147908.0000 - val_loss: 32938.3008\n",
      "Epoch 446/5000\n",
      "8/8 [==============================] - 7s 817ms/step - loss: 146229.9844 - val_loss: 31685.6074\n",
      "Epoch 447/5000\n",
      "8/8 [==============================] - 7s 815ms/step - loss: 142692.9219 - val_loss: 32177.7578\n",
      "Epoch 448/5000\n",
      "8/8 [==============================] - 6s 810ms/step - loss: 140097.5312 - val_loss: 28156.2598\n",
      "Epoch 449/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 144197.2188 - val_loss: 31484.2578\n",
      "Epoch 450/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 139512.6875 - val_loss: 32395.4746\n",
      "Epoch 451/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 144223.9688 - val_loss: 28507.9336\n",
      "Epoch 452/5000\n",
      "8/8 [==============================] - 7s 822ms/step - loss: 144161.7812 - val_loss: 30405.2188\n",
      "Epoch 453/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 145486.4844 - val_loss: 31567.5312\n",
      "Epoch 454/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 144059.5000 - val_loss: 31821.8320\n",
      "Epoch 455/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 147964.2188 - val_loss: 32020.3457\n",
      "Epoch 456/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 143149.9531 - val_loss: 32229.6172\n",
      "Epoch 457/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 142068.1719 - val_loss: 30885.1680\n",
      "Epoch 458/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 143871.7500 - val_loss: 31762.2891\n",
      "Epoch 459/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 141768.3281 - val_loss: 29995.6621\n",
      "Epoch 460/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 140306.9531 - val_loss: 31320.7812\n",
      "Epoch 461/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 143081.4844 - val_loss: 27731.1953\n",
      "Epoch 462/5000\n",
      "8/8 [==============================] - 6s 762ms/step - loss: 138317.0469 - val_loss: 31852.6348\n",
      "Epoch 463/5000\n",
      "8/8 [==============================] - 7s 846ms/step - loss: 138204.0000 - val_loss: 27757.3047\n",
      "Epoch 464/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 132497.5469 - val_loss: 30309.4297\n",
      "Epoch 465/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 137594.3281 - val_loss: 28161.8105\n",
      "Epoch 466/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 137729.2656 - val_loss: 30977.8984\n",
      "Epoch 467/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 142768.3281 - val_loss: 30046.6992\n",
      "Epoch 468/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 139827.6562 - val_loss: 30070.7910\n",
      "Epoch 469/5000\n",
      "8/8 [==============================] - 7s 886ms/step - loss: 138132.0312 - val_loss: 29937.0039\n",
      "Epoch 470/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 134031.6719 - val_loss: 28976.2793\n",
      "Epoch 471/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 133734.3281 - val_loss: 29492.0527\n",
      "Epoch 472/5000\n",
      "8/8 [==============================] - 7s 847ms/step - loss: 136193.6719 - val_loss: 30432.1289\n",
      "Epoch 473/5000\n",
      "8/8 [==============================] - 7s 822ms/step - loss: 138478.4688 - val_loss: 31945.4043\n",
      "Epoch 474/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 149781.0625 - val_loss: 32133.0625\n",
      "Epoch 475/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 145296.4375 - val_loss: 31753.4512\n",
      "Epoch 476/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 145097.4062 - val_loss: 32476.5176\n",
      "Epoch 477/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 143032.1406 - val_loss: 30839.0977\n",
      "Epoch 478/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 139783.5469 - val_loss: 30098.0000\n",
      "Epoch 479/5000\n",
      "8/8 [==============================] - 7s 841ms/step - loss: 141794.4688 - val_loss: 29453.1602\n",
      "Epoch 480/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 143330.1719 - val_loss: 30952.8926\n",
      "Epoch 481/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 147848.7656 - val_loss: 33911.8594\n",
      "Epoch 482/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 153423.4375 - val_loss: 33476.6211\n",
      "Epoch 483/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 140979.1562 - val_loss: 34025.7695\n",
      "Epoch 484/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 147444.9062 - val_loss: 31194.5996\n",
      "Epoch 485/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 140334.4531 - val_loss: 29806.1777\n",
      "Epoch 486/5000\n",
      "8/8 [==============================] - 6s 770ms/step - loss: 140677.5312 - val_loss: 34000.8242\n",
      "Epoch 487/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 142830.7344 - val_loss: 33901.3516\n",
      "Epoch 488/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 149513.4688 - val_loss: 34020.2617\n",
      "Epoch 489/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 151797.8438 - val_loss: 56473.3672\n",
      "Epoch 490/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 150397.9375 - val_loss: 41872.0508\n",
      "Epoch 491/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 145615.8438 - val_loss: 45623.1484\n",
      "Epoch 492/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 145368.8438 - val_loss: 36576.1094\n",
      "Epoch 493/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 143679.5938 - val_loss: 40466.5664\n",
      "Epoch 494/5000\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 140452.4688 - val_loss: 88887.4141\n",
      "Epoch 495/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 148745.6719 - val_loss: 61226.2539\n",
      "Epoch 496/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 151812.1562 - val_loss: 58553.5469\n",
      "Epoch 497/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 147163.3438 - val_loss: 48264.6602\n",
      "Epoch 498/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 151979.0781 - val_loss: 41557.4258\n",
      "Epoch 499/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 133096.4688 - val_loss: 59905.2617\n",
      "Epoch 500/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 139887.5781 - val_loss: 51273.7773\n",
      "Epoch 501/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 150487.3594 - val_loss: 102842.7422\n",
      "Epoch 502/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 171635.7812 - val_loss: 314835.5312\n",
      "Epoch 503/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 179005.6094 - val_loss: 105863.0000\n",
      "Epoch 504/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 186865.7344 - val_loss: 705455.4375\n",
      "Epoch 505/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 267698.3750 - val_loss: 177697.5781\n",
      "Epoch 506/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 215092.1719 - val_loss: 178136.2031\n",
      "Epoch 507/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 199131.2031 - val_loss: 346559.1875\n",
      "Epoch 508/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 199268.9688 - val_loss: 285562.1875\n",
      "Epoch 509/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 220822.2344 - val_loss: 329310.1875\n",
      "Epoch 510/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 196796.9219 - val_loss: 119931.6406\n",
      "Epoch 511/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 174416.8438 - val_loss: 115950.3203\n",
      "Epoch 512/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 181257.2031 - val_loss: 96525.6562\n",
      "Epoch 513/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 160296.2969 - val_loss: 121980.7109\n",
      "Epoch 514/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 158582.7500 - val_loss: 97225.1641\n",
      "Epoch 515/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 158273.7969 - val_loss: 55794.0469\n",
      "Epoch 516/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 153737.9844 - val_loss: 52341.5703\n",
      "Epoch 517/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 146816.4531 - val_loss: 39552.4492\n",
      "Epoch 518/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 799ms/step - loss: 148563.4375 - val_loss: 92271.7812\n",
      "Epoch 519/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 156104.5312 - val_loss: 106977.3203\n",
      "Epoch 520/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 150451.9219 - val_loss: 60961.1680\n",
      "Epoch 521/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 140868.5938 - val_loss: 44869.2031\n",
      "Epoch 522/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 146207.1094 - val_loss: 48220.1367\n",
      "Epoch 523/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 147573.4531 - val_loss: 40185.2148\n",
      "Epoch 524/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 141266.9375 - val_loss: 40500.4453\n",
      "Epoch 525/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 139088.1562 - val_loss: 36231.8867\n",
      "Epoch 526/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 139825.0312 - val_loss: 34721.1758\n",
      "Epoch 527/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 149430.2500 - val_loss: 37609.2734\n",
      "Epoch 528/5000\n",
      "8/8 [==============================] - 6s 770ms/step - loss: 149493.8906 - val_loss: 34810.8594\n",
      "Epoch 529/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 146663.4531 - val_loss: 32396.2129\n",
      "Epoch 530/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 145296.9375 - val_loss: 32348.1035\n",
      "Epoch 531/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 140900.2188 - val_loss: 33262.9766\n",
      "Epoch 532/5000\n",
      "8/8 [==============================] - 7s 837ms/step - loss: 138028.8281 - val_loss: 31039.4258\n",
      "Epoch 533/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 141276.4844 - val_loss: 30665.7500\n",
      "Epoch 534/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 141273.7969 - val_loss: 31229.2168\n",
      "Epoch 535/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 145086.4062 - val_loss: 32075.4082\n",
      "Epoch 536/5000\n",
      "8/8 [==============================] - 7s 818ms/step - loss: 143427.9062 - val_loss: 31030.3691\n",
      "Epoch 537/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 140208.2344 - val_loss: 30736.5488\n",
      "Epoch 538/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 141958.0781 - val_loss: 32806.6016\n",
      "Epoch 539/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 137616.6406 - val_loss: 30622.6992\n",
      "Epoch 540/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 139612.5781 - val_loss: 31236.5312\n",
      "Epoch 541/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 142183.2188 - val_loss: 29227.8672\n",
      "Epoch 542/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 140888.5781 - val_loss: 28768.6523\n",
      "Epoch 543/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 137589.7031 - val_loss: 30660.1797\n",
      "Epoch 544/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 137933.1094 - val_loss: 32240.1211\n",
      "Epoch 545/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 142994.9844 - val_loss: 36087.9805\n",
      "Epoch 546/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 139085.9062 - val_loss: 44464.3906\n",
      "Epoch 547/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 140010.8281 - val_loss: 39519.0781\n",
      "Epoch 548/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 137568.2500 - val_loss: 32375.4473\n",
      "Epoch 549/5000\n",
      "8/8 [==============================] - 6s 760ms/step - loss: 137342.8750 - val_loss: 37713.2148\n",
      "Epoch 550/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 137507.5312 - val_loss: 29926.2500\n",
      "Epoch 551/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 134835.7656 - val_loss: 32816.6953\n",
      "Epoch 552/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 142359.4062 - val_loss: 31098.2734\n",
      "Epoch 553/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 136573.4688 - val_loss: 28614.5000\n",
      "Epoch 554/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 129215.0938 - val_loss: 29657.0332\n",
      "Epoch 555/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 136868.8594 - val_loss: 28597.9102\n",
      "Epoch 556/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 139154.5938 - val_loss: 29539.4590\n",
      "Epoch 557/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 135082.6250 - val_loss: 26871.7559\n",
      "Epoch 558/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 134899.0156 - val_loss: 28063.8711\n",
      "Epoch 559/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 140718.5312 - val_loss: 28618.0918\n",
      "Epoch 560/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 134680.9844 - val_loss: 27419.8379\n",
      "Epoch 561/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 129889.2500 - val_loss: 26391.0918\n",
      "Epoch 562/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 136251.0000 - val_loss: 29886.1465\n",
      "Epoch 563/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 134726.1875 - val_loss: 29665.2227\n",
      "Epoch 564/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 137981.0938 - val_loss: 29180.9492\n",
      "Epoch 565/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 129111.6797 - val_loss: 27701.1699\n",
      "Epoch 566/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 132587.4219 - val_loss: 30079.8848\n",
      "Epoch 567/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 141052.8281 - val_loss: 29559.9277\n",
      "Epoch 568/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 135442.1719 - val_loss: 29890.5742\n",
      "Epoch 569/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 137790.2344 - val_loss: 29906.7910\n",
      "Epoch 570/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 131921.3438 - val_loss: 30651.8535\n",
      "Epoch 571/5000\n",
      "8/8 [==============================] - 7s 851ms/step - loss: 134883.8594 - val_loss: 28706.4453\n",
      "Epoch 572/5000\n",
      "8/8 [==============================] - 7s 855ms/step - loss: 130529.0234 - val_loss: 28800.0742\n",
      "Epoch 573/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 136319.9062 - val_loss: 27342.4199\n",
      "Epoch 574/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 136455.5938 - val_loss: 29186.0508\n",
      "Epoch 575/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 134033.9531 - val_loss: 27211.0254\n",
      "Epoch 576/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 132468.5938 - val_loss: 32095.4414\n",
      "Epoch 577/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 134681.7344 - val_loss: 29938.4414\n",
      "Epoch 578/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 136371.3594 - val_loss: 29864.8359\n",
      "Epoch 579/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 126722.6328 - val_loss: 28869.1133\n",
      "Epoch 580/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 131708.1094 - val_loss: 28200.5938\n",
      "Epoch 581/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 127095.7734 - val_loss: 29098.9199\n",
      "Epoch 582/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 129112.9844 - val_loss: 28536.0039\n",
      "Epoch 583/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 137288.3281 - val_loss: 28200.2852\n",
      "Epoch 584/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 140676.4531 - val_loss: 32497.7871\n",
      "Epoch 585/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 139142.2656 - val_loss: 28530.3828\n",
      "Epoch 586/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 132936.5938 - val_loss: 30297.5312\n",
      "Epoch 587/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 141383.3906 - val_loss: 31435.8555\n",
      "Epoch 588/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 139271.4688 - val_loss: 28594.9414\n",
      "Epoch 589/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 137651.1719 - val_loss: 28536.4160\n",
      "Epoch 590/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 137461.6562 - val_loss: 30545.7246\n",
      "Epoch 591/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 137853.4531 - val_loss: 27741.2441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 592/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 132075.7344 - val_loss: 29072.1445\n",
      "Epoch 593/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 130154.3750 - val_loss: 29633.8477\n",
      "Epoch 594/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 133831.0156 - val_loss: 28330.6328\n",
      "Epoch 595/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 135159.2969 - val_loss: 29854.6328\n",
      "Epoch 596/5000\n",
      "8/8 [==============================] - 6s 767ms/step - loss: 136206.3750 - val_loss: 27395.8652\n",
      "Epoch 597/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 132576.7344 - val_loss: 27253.1914\n",
      "Epoch 598/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 134033.4531 - val_loss: 27505.5000\n",
      "Epoch 599/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 132556.5156 - val_loss: 27806.6445\n",
      "Epoch 600/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 128105.5547 - val_loss: 26584.0020\n",
      "Epoch 601/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 128791.1016 - val_loss: 26780.7422\n",
      "Epoch 602/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 132510.9531 - val_loss: 28471.7012\n",
      "Epoch 603/5000\n",
      "8/8 [==============================] - 7s 813ms/step - loss: 133733.4219 - val_loss: 30409.0957\n",
      "Epoch 604/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 134234.9062 - val_loss: 26146.6133\n",
      "Epoch 605/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 132870.0469 - val_loss: 25888.0801\n",
      "Epoch 606/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 130378.0391 - val_loss: 28788.6660\n",
      "Epoch 607/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 134465.3750 - val_loss: 29491.0293\n",
      "Epoch 608/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 135617.6094 - val_loss: 31440.5332\n",
      "Epoch 609/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 134967.8125 - val_loss: 31732.1934\n",
      "Epoch 610/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 137626.1875 - val_loss: 29571.7949\n",
      "Epoch 611/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 134551.6562 - val_loss: 29044.2266\n",
      "Epoch 612/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 136245.5312 - val_loss: 28976.1836\n",
      "Epoch 613/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 139764.6406 - val_loss: 29275.1055\n",
      "Epoch 614/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 132323.4531 - val_loss: 29545.2402\n",
      "Epoch 615/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 135674.3906 - val_loss: 32929.9258\n",
      "Epoch 616/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 138492.7969 - val_loss: 28420.7520\n",
      "Epoch 617/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 136231.1406 - val_loss: 26961.3867\n",
      "Epoch 618/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 133089.2656 - val_loss: 26914.6367\n",
      "Epoch 619/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 135989.4844 - val_loss: 28827.0879\n",
      "Epoch 620/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 130496.0234 - val_loss: 29474.7949\n",
      "Epoch 621/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 130251.0312 - val_loss: 26748.5312\n",
      "Epoch 622/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 136861.9219 - val_loss: 30686.7070\n",
      "Epoch 623/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 136598.0625 - val_loss: 28728.3535\n",
      "Epoch 624/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 130688.0469 - val_loss: 28716.2832\n",
      "Epoch 625/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 135939.2656 - val_loss: 30372.8711\n",
      "Epoch 626/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 133651.4844 - val_loss: 28286.4492\n",
      "Epoch 627/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 136573.3125 - val_loss: 30184.1934\n",
      "Epoch 628/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 130655.4297 - val_loss: 27743.9629\n",
      "Epoch 629/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 131162.8438 - val_loss: 29516.3262\n",
      "Epoch 630/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 131838.2188 - val_loss: 26753.6699\n",
      "Epoch 631/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 126601.9609 - val_loss: 27894.9707\n",
      "Epoch 632/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 135203.1875 - val_loss: 28194.0723\n",
      "Epoch 633/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 129425.6016 - val_loss: 28388.9355\n",
      "Epoch 634/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 133895.8125 - val_loss: 26215.7051\n",
      "Epoch 635/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 127777.1016 - val_loss: 27772.9004\n",
      "Epoch 636/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 129764.8672 - val_loss: 28453.4648\n",
      "Epoch 637/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 136080.0000 - val_loss: 28985.7812\n",
      "Epoch 638/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 140924.7969 - val_loss: 29071.8047\n",
      "Epoch 639/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 136315.2344 - val_loss: 29104.1621\n",
      "Epoch 640/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 131714.3438 - val_loss: 28056.1289\n",
      "Epoch 641/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 136241.3594 - val_loss: 35638.0703\n",
      "Epoch 642/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 134083.8125 - val_loss: 32114.2129\n",
      "Epoch 643/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 137628.2344 - val_loss: 39317.4609\n",
      "Epoch 644/5000\n",
      "8/8 [==============================] - 6s 763ms/step - loss: 139595.9219 - val_loss: 34943.1641\n",
      "Epoch 645/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 140320.5312 - val_loss: 30330.6348\n",
      "Epoch 646/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 134099.7500 - val_loss: 33469.9180\n",
      "Epoch 647/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 132086.6094 - val_loss: 28501.3320\n",
      "Epoch 648/5000\n",
      "8/8 [==============================] - 7s 815ms/step - loss: 131094.9531 - val_loss: 29981.9590\n",
      "Epoch 649/5000\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 135667.7500 - val_loss: 36517.9453\n",
      "Epoch 650/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 131751.7031 - val_loss: 31758.8574\n",
      "Epoch 651/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 131592.4844 - val_loss: 29913.2949\n",
      "Epoch 652/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 132466.5469 - val_loss: 26967.7930\n",
      "Epoch 653/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 125684.4219 - val_loss: 29056.9590\n",
      "Epoch 654/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 137471.4219 - val_loss: 28730.8379\n",
      "Epoch 655/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 138106.5312 - val_loss: 27688.8516\n",
      "Epoch 656/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 134006.2500 - val_loss: 30925.6230\n",
      "Epoch 657/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 134147.7500 - val_loss: 29694.2051\n",
      "Epoch 658/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 130968.2969 - val_loss: 28646.5918\n",
      "Epoch 659/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 131312.6562 - val_loss: 28331.2695\n",
      "Epoch 660/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 134070.8281 - val_loss: 28695.4629\n",
      "Epoch 661/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 134685.2812 - val_loss: 29578.4414\n",
      "Epoch 662/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 135051.9688 - val_loss: 29910.2559\n",
      "Epoch 663/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 130295.1328 - val_loss: 30746.0625\n",
      "Epoch 664/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 135032.5156 - val_loss: 31846.2539\n",
      "Epoch 665/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 135060.6562 - val_loss: 30555.2070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 666/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 129509.9062 - val_loss: 31457.7441\n",
      "Epoch 667/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 132623.4688 - val_loss: 28469.7461\n",
      "Epoch 668/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 132607.2344 - val_loss: 31491.5801\n",
      "Epoch 669/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 134850.2656 - val_loss: 29782.8496\n",
      "Epoch 670/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 135260.2969 - val_loss: 31453.0605\n",
      "Epoch 671/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 132372.6719 - val_loss: 26762.3008\n",
      "Epoch 672/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 129449.6016 - val_loss: 28110.7402\n",
      "Epoch 673/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 136508.0469 - val_loss: 31098.6895\n",
      "Epoch 674/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 140162.5312 - val_loss: 32195.8613\n",
      "Epoch 675/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 132616.7031 - val_loss: 30841.4902\n",
      "Epoch 676/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 136695.0938 - val_loss: 30777.7461\n",
      "Epoch 677/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 133665.3594 - val_loss: 27433.6113\n",
      "Epoch 678/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 128226.0000 - val_loss: 27381.3672\n",
      "Epoch 679/5000\n",
      "8/8 [==============================] - 7s 813ms/step - loss: 133756.2031 - val_loss: 29224.0000\n",
      "Epoch 680/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 130231.5156 - val_loss: 28645.0898\n",
      "Epoch 681/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 134407.3125 - val_loss: 28419.0703\n",
      "Epoch 682/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 132820.6719 - val_loss: 29506.6934\n",
      "Epoch 683/5000\n",
      "8/8 [==============================] - 7s 816ms/step - loss: 139092.5938 - val_loss: 30285.4707\n",
      "Epoch 684/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 140042.7812 - val_loss: 27391.2383\n",
      "Epoch 685/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 132541.5781 - val_loss: 32172.2793\n",
      "Epoch 686/5000\n",
      "8/8 [==============================] - 6s 771ms/step - loss: 138537.9531 - val_loss: 31386.8672\n",
      "Epoch 687/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 137187.1406 - val_loss: 31270.4922\n",
      "Epoch 688/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 141532.1094 - val_loss: 29752.7188\n",
      "Epoch 689/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 138329.8281 - val_loss: 29983.6289\n",
      "Epoch 690/5000\n",
      "8/8 [==============================] - 7s 917ms/step - loss: 131803.0156 - val_loss: 28350.8770\n",
      "Epoch 691/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 144861.2969 - val_loss: 34017.3047\n",
      "Epoch 692/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 139757.8594 - val_loss: 31841.4082\n",
      "Epoch 693/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 135784.1875 - val_loss: 30875.7246\n",
      "Epoch 694/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 136562.1406 - val_loss: 35732.7500\n",
      "Epoch 695/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 131333.1562 - val_loss: 36334.1250\n",
      "Epoch 696/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 131899.2656 - val_loss: 31023.2910\n",
      "Epoch 697/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 134269.3125 - val_loss: 30324.9043\n",
      "Epoch 698/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 136947.3438 - val_loss: 36518.7266\n",
      "Epoch 699/5000\n",
      "8/8 [==============================] - 7s 843ms/step - loss: 142107.0625 - val_loss: 33049.9805\n",
      "Epoch 700/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 138480.3125 - val_loss: 31548.6504\n",
      "Epoch 701/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 129923.9688 - val_loss: 30396.9629\n",
      "Epoch 702/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 131270.5625 - val_loss: 30763.3359\n",
      "Epoch 703/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 132419.7656 - val_loss: 28783.6465\n",
      "Epoch 704/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 134205.7500 - val_loss: 30147.0801\n",
      "Epoch 705/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 142107.9062 - val_loss: 30308.4883\n",
      "Epoch 706/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 141037.8906 - val_loss: 30404.3262\n",
      "Epoch 707/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 135954.2812 - val_loss: 30725.0723\n",
      "Epoch 708/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 138527.8281 - val_loss: 28778.6973\n",
      "Epoch 709/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 136901.1250 - val_loss: 30179.7441\n",
      "Epoch 710/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 141193.7031 - val_loss: 27037.4414\n",
      "Epoch 711/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 136595.6875 - val_loss: 32426.4629\n",
      "Epoch 712/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 150673.7188 - val_loss: 30680.3887\n",
      "Epoch 713/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 141569.7500 - val_loss: 35445.3984\n",
      "Epoch 714/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 136157.7969 - val_loss: 42766.2773\n",
      "Epoch 715/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 146163.5625 - val_loss: 29977.8848\n",
      "Epoch 716/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 139568.7969 - val_loss: 33673.1875\n",
      "Epoch 717/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 142036.9844 - val_loss: 31721.9316\n",
      "Epoch 718/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 138016.0156 - val_loss: 33189.6602\n",
      "Epoch 719/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 138994.4688 - val_loss: 29312.8340\n",
      "Epoch 720/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 140596.0625 - val_loss: 28747.8008\n",
      "Epoch 721/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 139695.8281 - val_loss: 31079.1289\n",
      "Epoch 722/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 138319.3281 - val_loss: 31541.8047\n",
      "Epoch 723/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 138700.4688 - val_loss: 32386.3242\n",
      "Epoch 724/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 140232.2969 - val_loss: 29127.9883\n",
      "Epoch 725/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 138652.2031 - val_loss: 32102.8867\n",
      "Epoch 726/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 138610.4688 - val_loss: 30641.8770\n",
      "Epoch 727/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 143305.5312 - val_loss: 36530.8398\n",
      "Epoch 728/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 134697.0938 - val_loss: 37171.8633\n",
      "Epoch 729/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 132046.9844 - val_loss: 31739.2734\n",
      "Epoch 730/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 142051.3281 - val_loss: 28999.5762\n",
      "Epoch 731/5000\n",
      "8/8 [==============================] - 6s 771ms/step - loss: 144909.9688 - val_loss: 29690.2520\n",
      "Epoch 732/5000\n",
      "8/8 [==============================] - 7s 833ms/step - loss: 144061.9844 - val_loss: 30096.3730\n",
      "Epoch 733/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 141952.5469 - val_loss: 34270.2969\n",
      "Epoch 734/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 140939.5000 - val_loss: 31504.6758\n",
      "Epoch 735/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 141000.3438 - val_loss: 31168.2051\n",
      "Epoch 736/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 146055.0938 - val_loss: 30645.9961\n",
      "Epoch 737/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 143192.0312 - val_loss: 33554.8945\n",
      "Epoch 738/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 137635.8281 - val_loss: 30345.8086\n",
      "Epoch 739/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 137995.7500 - val_loss: 27401.9141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 137214.4062 - val_loss: 28765.7871\n",
      "Epoch 741/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 137557.0156 - val_loss: 31114.0605\n",
      "Epoch 742/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 140567.6875 - val_loss: 27909.5059\n",
      "Epoch 743/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 136820.4375 - val_loss: 30862.1133\n",
      "Epoch 744/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 139151.2344 - val_loss: 32100.3203\n",
      "Epoch 745/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 147161.2656 - val_loss: 31542.3574\n",
      "Epoch 746/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 145984.3594 - val_loss: 30144.7402\n",
      "Epoch 747/5000\n",
      "8/8 [==============================] - 6s 770ms/step - loss: 137493.6406 - val_loss: 29050.6367\n",
      "Epoch 748/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 143515.9688 - val_loss: 31175.9980\n",
      "Epoch 749/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 135750.7969 - val_loss: 28473.5664\n",
      "Epoch 750/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 136592.2500 - val_loss: 27447.4590\n",
      "Epoch 751/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 132449.2969 - val_loss: 29225.4824\n",
      "Epoch 752/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 139658.5625 - val_loss: 32005.3008\n",
      "Epoch 753/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 136081.1719 - val_loss: 32319.5000\n",
      "Epoch 754/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 140059.2812 - val_loss: 35322.1094\n",
      "Epoch 755/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 147522.8906 - val_loss: 35808.2734\n",
      "Epoch 756/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 139933.2031 - val_loss: 34801.1836\n",
      "Epoch 757/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 145047.5625 - val_loss: 38802.9883\n",
      "Epoch 758/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 141817.0781 - val_loss: 32979.6094\n",
      "Epoch 759/5000\n",
      "8/8 [==============================] - 6s 771ms/step - loss: 146022.0938 - val_loss: 36349.8984\n",
      "Epoch 760/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 146998.1094 - val_loss: 35846.9922\n",
      "Epoch 761/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 141792.2500 - val_loss: 33127.5273\n",
      "Epoch 762/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 146503.9531 - val_loss: 38091.0156\n",
      "Epoch 763/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 148613.9531 - val_loss: 42063.1367\n",
      "Epoch 764/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 144068.8906 - val_loss: 54764.4297\n",
      "Epoch 765/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 140570.4844 - val_loss: 52094.8008\n",
      "Epoch 766/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 142547.0938 - val_loss: 33613.7109\n",
      "Epoch 767/5000\n",
      "8/8 [==============================] - 7s 877ms/step - loss: 133181.5469 - val_loss: 36776.1992\n",
      "Epoch 768/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 139857.2031 - val_loss: 33280.9023\n",
      "Epoch 769/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 134392.7500 - val_loss: 31339.4141\n",
      "Epoch 770/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 131961.8125 - val_loss: 33326.3164\n",
      "Epoch 771/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 145275.5781 - val_loss: 32491.2441\n",
      "Epoch 772/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 131841.3438 - val_loss: 33559.0898\n",
      "Epoch 773/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 138239.6719 - val_loss: 35784.7305\n",
      "Epoch 774/5000\n",
      "8/8 [==============================] - 7s 822ms/step - loss: 141287.0000 - val_loss: 42344.7734\n",
      "Epoch 775/5000\n",
      "8/8 [==============================] - 7s 861ms/step - loss: 142577.5938 - val_loss: 34357.1914\n",
      "Epoch 776/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 140307.8594 - val_loss: 28732.4629\n",
      "Epoch 777/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 134949.4062 - val_loss: 29461.1074\n",
      "Epoch 778/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 137386.2656 - val_loss: 30056.5898\n",
      "Epoch 779/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 134708.8125 - val_loss: 29497.4062\n",
      "Epoch 780/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 139592.5469 - val_loss: 31839.4121\n",
      "Epoch 781/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 142219.7969 - val_loss: 28813.8984\n",
      "Epoch 782/5000\n",
      "8/8 [==============================] - 6s 768ms/step - loss: 137068.0312 - val_loss: 28601.6113\n",
      "Epoch 783/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 139852.5938 - val_loss: 30558.9785\n",
      "Epoch 784/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 140284.8125 - val_loss: 28782.4043\n",
      "Epoch 785/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 142368.6406 - val_loss: 28788.7500\n",
      "Epoch 786/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 139885.8281 - val_loss: 32858.3906\n",
      "Epoch 787/5000\n",
      "8/8 [==============================] - 7s 856ms/step - loss: 143036.9688 - val_loss: 29012.0371\n",
      "Epoch 788/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 136927.4688 - val_loss: 26987.6602\n",
      "Epoch 789/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 129673.2578 - val_loss: 28208.8359\n",
      "Epoch 790/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 132666.1875 - val_loss: 29028.4766\n",
      "Epoch 791/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 131845.2031 - val_loss: 26513.6270\n",
      "Epoch 792/5000\n",
      "8/8 [==============================] - 6s 771ms/step - loss: 131493.3125 - val_loss: 26943.2227\n",
      "Epoch 793/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 132823.6094 - val_loss: 30514.7539\n",
      "Epoch 794/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 137212.9688 - val_loss: 30940.7793\n",
      "Epoch 795/5000\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 136147.5625 - val_loss: 26466.5918\n",
      "Epoch 796/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 130852.5469 - val_loss: 27417.3457\n",
      "Epoch 797/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 131295.8125 - val_loss: 27237.5488\n",
      "Epoch 798/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 134779.9688 - val_loss: 29440.9863\n",
      "Epoch 799/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 139215.9375 - val_loss: 27372.5879\n",
      "Epoch 800/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 132661.8281 - val_loss: 27717.2695\n",
      "Epoch 801/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 137395.2031 - val_loss: 29294.6426\n",
      "Epoch 802/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 137070.5469 - val_loss: 26118.5117\n",
      "Epoch 803/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 128759.9062 - val_loss: 26658.1348\n",
      "Epoch 804/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 129513.8359 - val_loss: 26825.5977\n",
      "Epoch 805/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 129889.8203 - val_loss: 26551.2793\n",
      "Epoch 806/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 124959.6328 - val_loss: 26134.7324\n",
      "Epoch 807/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 129717.2656 - val_loss: 25924.8184\n",
      "Epoch 808/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 129905.2109 - val_loss: 28639.2715\n",
      "Epoch 809/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 134647.6094 - val_loss: 27189.1230\n",
      "Epoch 810/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 135158.1875 - val_loss: 27675.1465\n",
      "Epoch 811/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 133110.0781 - val_loss: 28117.7891\n",
      "Epoch 812/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 132091.8281 - val_loss: 26703.5039\n",
      "Epoch 813/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 134984.9844 - val_loss: 29946.3828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 814/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 137345.9062 - val_loss: 30544.8203\n",
      "Epoch 815/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 130214.0312 - val_loss: 27739.4629\n",
      "Epoch 816/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 133366.4531 - val_loss: 27774.6289\n",
      "Epoch 817/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 131215.8906 - val_loss: 32618.9805\n",
      "Epoch 818/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 141989.6562 - val_loss: 31544.2559\n",
      "Epoch 819/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 129299.8906 - val_loss: 27205.2285\n",
      "Epoch 820/5000\n",
      "8/8 [==============================] - 6s 770ms/step - loss: 130148.9141 - val_loss: 30325.3457\n",
      "Epoch 821/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 135351.8906 - val_loss: 29128.8633\n",
      "Epoch 822/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 138075.6250 - val_loss: 28357.4941\n",
      "Epoch 823/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 131435.0938 - val_loss: 28843.3887\n",
      "Epoch 824/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 132669.0625 - val_loss: 32697.8164\n",
      "Epoch 825/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 138520.5938 - val_loss: 25913.6426\n",
      "Epoch 826/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 129105.1250 - val_loss: 28291.9512\n",
      "Epoch 827/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 135515.6094 - val_loss: 29976.3184\n",
      "Epoch 828/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 130916.8984 - val_loss: 28378.8242\n",
      "Epoch 829/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 130548.0781 - val_loss: 29317.3145\n",
      "Epoch 830/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 134729.1875 - val_loss: 30297.0352\n",
      "Epoch 831/5000\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 131369.6719 - val_loss: 28880.8828\n",
      "Epoch 832/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 131584.4688 - val_loss: 26737.1250\n",
      "Epoch 833/5000\n",
      "8/8 [==============================] - 6s 766ms/step - loss: 132260.4844 - val_loss: 27903.0957\n",
      "Epoch 834/5000\n",
      "8/8 [==============================] - 7s 815ms/step - loss: 133150.5781 - val_loss: 28882.6543\n",
      "Epoch 835/5000\n",
      "8/8 [==============================] - 6s 769ms/step - loss: 133880.5469 - val_loss: 30038.4688\n",
      "Epoch 836/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 128456.4922 - val_loss: 27071.4004\n",
      "Epoch 837/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 137841.6562 - val_loss: 28755.1035\n",
      "Epoch 838/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 134480.1094 - val_loss: 29178.7812\n",
      "Epoch 839/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 136841.6406 - val_loss: 27979.0762\n",
      "Epoch 840/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 132330.7500 - val_loss: 33142.7969\n",
      "Epoch 841/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 132124.1406 - val_loss: 28587.0898\n",
      "Epoch 842/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 137618.0625 - val_loss: 30418.3340\n",
      "Epoch 843/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 136347.9531 - val_loss: 27809.4453\n",
      "Epoch 844/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 133040.0156 - val_loss: 26198.5391\n",
      "Epoch 845/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 130819.3594 - val_loss: 28589.2129\n",
      "Epoch 846/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 134356.0312 - val_loss: 30698.1895\n",
      "Epoch 847/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 137592.4219 - val_loss: 28065.3574\n",
      "Epoch 848/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 131349.8438 - val_loss: 28509.2734\n",
      "Epoch 849/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 129435.3594 - val_loss: 26445.4414\n",
      "Epoch 850/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 138523.4531 - val_loss: 27665.0078\n",
      "Epoch 851/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 130570.7812 - val_loss: 25694.7695\n",
      "Epoch 852/5000\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 132311.0312 - val_loss: 28011.7578\n",
      "Epoch 853/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 136761.4375 - val_loss: 30172.1797\n",
      "Epoch 854/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 137589.1094 - val_loss: 27484.5293\n",
      "Epoch 855/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 129374.2422 - val_loss: 37226.0586\n",
      "Epoch 856/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 132204.3594 - val_loss: 31022.5117\n",
      "Epoch 857/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 132160.8594 - val_loss: 30800.1660\n",
      "Epoch 858/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 143138.4844 - val_loss: 33247.9336\n",
      "Epoch 859/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 137587.5312 - val_loss: 29393.6680\n",
      "Epoch 860/5000\n",
      "8/8 [==============================] - 6s 810ms/step - loss: 130893.7031 - val_loss: 31558.0586\n",
      "Epoch 861/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 136547.9688 - val_loss: 28507.3301\n",
      "Epoch 862/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 136511.0469 - val_loss: 30151.6934\n",
      "Epoch 863/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 140189.2656 - val_loss: 26703.6777\n",
      "Epoch 864/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 128635.3750 - val_loss: 30627.9395\n",
      "Epoch 865/5000\n",
      "8/8 [==============================] - 7s 830ms/step - loss: 136056.4531 - val_loss: 29082.2051\n",
      "Epoch 866/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 135187.6719 - val_loss: 27403.9375\n",
      "Epoch 867/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 132739.1094 - val_loss: 28346.7324\n",
      "Epoch 868/5000\n",
      "8/8 [==============================] - 7s 815ms/step - loss: 130525.5781 - val_loss: 32279.4160\n",
      "Epoch 869/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 139977.3281 - val_loss: 34456.3945\n",
      "Epoch 870/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 138719.3438 - val_loss: 29787.2324\n",
      "Epoch 871/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 134254.2188 - val_loss: 32985.3320\n",
      "Epoch 872/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 142927.2500 - val_loss: 30404.7441\n",
      "Epoch 873/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 134644.5312 - val_loss: 30940.8887\n",
      "Epoch 874/5000\n",
      "8/8 [==============================] - 6s 770ms/step - loss: 140542.2344 - val_loss: 27540.6133\n",
      "Epoch 875/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 136499.8594 - val_loss: 26275.7246\n",
      "Epoch 876/5000\n",
      "8/8 [==============================] - 7s 913ms/step - loss: 129657.8906 - val_loss: 30617.5215\n",
      "Epoch 877/5000\n",
      "8/8 [==============================] - 7s 836ms/step - loss: 130324.2031 - val_loss: 30201.4492\n",
      "Epoch 878/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 134804.6719 - val_loss: 30406.8164\n",
      "Epoch 879/5000\n",
      "8/8 [==============================] - 6s 768ms/step - loss: 138415.8281 - val_loss: 27222.7461\n",
      "Epoch 880/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 126800.7734 - val_loss: 28647.6602\n",
      "Epoch 881/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 134630.2812 - val_loss: 26723.1172\n",
      "Epoch 882/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 129824.0703 - val_loss: 25086.1484\n",
      "Epoch 883/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 129570.8203 - val_loss: 27006.2383\n",
      "Epoch 884/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 134523.9219 - val_loss: 29516.6543\n",
      "Epoch 885/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 139682.7812 - val_loss: 28095.3125\n",
      "Epoch 886/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 130944.3203 - val_loss: 30560.5723\n",
      "Epoch 887/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 128489.5703 - val_loss: 27817.8379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 888/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 133010.6094 - val_loss: 29343.2949\n",
      "Epoch 889/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 131455.7188 - val_loss: 31263.3320\n",
      "Epoch 890/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 137304.0469 - val_loss: 29045.4355\n",
      "Epoch 891/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 129257.6172 - val_loss: 28518.7812\n",
      "Epoch 892/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 134165.7031 - val_loss: 27518.5332\n",
      "Epoch 893/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 132802.5781 - val_loss: 31391.4375\n",
      "Epoch 894/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 135091.8594 - val_loss: 29282.4766\n",
      "Epoch 895/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 135969.0156 - val_loss: 29482.3691\n",
      "Epoch 896/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 132663.5469 - val_loss: 28843.7207\n",
      "Epoch 897/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 135169.1094 - val_loss: 28198.9805\n",
      "Epoch 898/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 124298.2344 - val_loss: 25141.0801\n",
      "Epoch 899/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 128634.4844 - val_loss: 28281.0332\n",
      "Epoch 900/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 132282.8594 - val_loss: 24754.3828\n",
      "Epoch 901/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 131648.6875 - val_loss: 28637.1270\n",
      "Epoch 902/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 128558.3203 - val_loss: 27750.6191\n",
      "Epoch 903/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 128022.9922 - val_loss: 26392.9160\n",
      "Epoch 904/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 133677.0781 - val_loss: 28642.8086\n",
      "Epoch 905/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 130949.0312 - val_loss: 26902.1582\n",
      "Epoch 906/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 130876.6094 - val_loss: 28255.2812\n",
      "Epoch 907/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 132829.7188 - val_loss: 26174.0449\n",
      "Epoch 908/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 130220.7109 - val_loss: 27362.9961\n",
      "Epoch 909/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 126553.1562 - val_loss: 25965.7383\n",
      "Epoch 910/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 129655.1172 - val_loss: 27284.0762\n",
      "Epoch 911/5000\n",
      "8/8 [==============================] - 7s 851ms/step - loss: 124890.5469 - val_loss: 26424.3184\n",
      "Epoch 912/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 125088.2969 - val_loss: 30851.9297\n",
      "Epoch 913/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 129537.1797 - val_loss: 25446.7461\n",
      "Epoch 914/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 124741.7031 - val_loss: 25376.2617\n",
      "Epoch 915/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 128261.0391 - val_loss: 24214.9434\n",
      "Epoch 916/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 127317.2969 - val_loss: 27018.5996\n",
      "Epoch 917/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 128896.0312 - val_loss: 25083.8984\n",
      "Epoch 918/5000\n",
      "8/8 [==============================] - 7s 886ms/step - loss: 126919.5469 - val_loss: 25488.0371\n",
      "Epoch 919/5000\n",
      "8/8 [==============================] - 7s 843ms/step - loss: 129336.8438 - val_loss: 27195.2129\n",
      "Epoch 920/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 129903.1406 - val_loss: 25788.9492\n",
      "Epoch 921/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 123486.2500 - val_loss: 26337.5371\n",
      "Epoch 922/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 124465.5000 - val_loss: 25003.7676\n",
      "Epoch 923/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 124738.8984 - val_loss: 23454.1953\n",
      "Epoch 924/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 125291.6328 - val_loss: 28599.1230\n",
      "Epoch 925/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 128058.6016 - val_loss: 23129.7715\n",
      "Epoch 926/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 126077.7578 - val_loss: 28239.6211\n",
      "Epoch 927/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 134035.0156 - val_loss: 26050.6836\n",
      "Epoch 928/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 129349.8203 - val_loss: 27140.1328\n",
      "Epoch 929/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 130880.2188 - val_loss: 26434.5820\n",
      "Epoch 930/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 129762.9766 - val_loss: 30728.5801\n",
      "Epoch 931/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 129495.6250 - val_loss: 25444.4492\n",
      "Epoch 932/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 131701.4688 - val_loss: 29947.9590\n",
      "Epoch 933/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 126297.1953 - val_loss: 26754.1914\n",
      "Epoch 934/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 123671.6016 - val_loss: 25368.5000\n",
      "Epoch 935/5000\n",
      "8/8 [==============================] - 7s 814ms/step - loss: 126601.1094 - val_loss: 26545.8867\n",
      "Epoch 936/5000\n",
      "8/8 [==============================] - 6s 809ms/step - loss: 127991.2344 - val_loss: 28471.8047\n",
      "Epoch 937/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 125792.7500 - val_loss: 26712.2461\n",
      "Epoch 938/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 128290.1641 - val_loss: 27764.5703\n",
      "Epoch 939/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 131007.8516 - val_loss: 36574.3047\n",
      "Epoch 940/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 124539.0312 - val_loss: 24586.2324\n",
      "Epoch 941/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 119115.7109 - val_loss: 31010.0762\n",
      "Epoch 942/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 125995.4688 - val_loss: 28079.7617\n",
      "Epoch 943/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 131423.1406 - val_loss: 30939.3789\n",
      "Epoch 944/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 123359.0781 - val_loss: 26139.8555\n",
      "Epoch 945/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 130296.1172 - val_loss: 27044.7773\n",
      "Epoch 946/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 129323.5000 - val_loss: 32529.4277\n",
      "Epoch 947/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 126886.7812 - val_loss: 30002.6211\n",
      "Epoch 948/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 130612.2109 - val_loss: 30144.2422\n",
      "Epoch 949/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 135425.5312 - val_loss: 32231.7227\n",
      "Epoch 950/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 133602.9688 - val_loss: 33421.0508\n",
      "Epoch 951/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 127493.6641 - val_loss: 28425.0254\n",
      "Epoch 952/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 127900.4766 - val_loss: 28642.9824\n",
      "Epoch 953/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 134065.0469 - val_loss: 24990.4824\n",
      "Epoch 954/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 124324.1172 - val_loss: 25824.5840\n",
      "Epoch 955/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 128251.5078 - val_loss: 29327.3555\n",
      "Epoch 956/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 129459.7031 - val_loss: 27496.9629\n",
      "Epoch 957/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 132621.3281 - val_loss: 32545.5117\n",
      "Epoch 958/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 136412.2344 - val_loss: 26529.9551\n",
      "Epoch 959/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 129150.3203 - val_loss: 27416.6133\n",
      "Epoch 960/5000\n",
      "8/8 [==============================] - 7s 821ms/step - loss: 122384.5391 - val_loss: 33620.4258\n",
      "Epoch 961/5000\n",
      "8/8 [==============================] - 7s 818ms/step - loss: 123959.3984 - val_loss: 29700.4395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 962/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 133994.8125 - val_loss: 26710.9473\n",
      "Epoch 963/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 128355.0469 - val_loss: 24918.5801\n",
      "Epoch 964/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 123651.8359 - val_loss: 26463.8398\n",
      "Epoch 965/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 124259.0469 - val_loss: 26318.1543\n",
      "Epoch 966/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 124697.5859 - val_loss: 25158.8867\n",
      "Epoch 967/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 129231.7969 - val_loss: 27452.9160\n",
      "Epoch 968/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 128063.1250 - val_loss: 26806.0215\n",
      "Epoch 969/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 128334.5859 - val_loss: 29800.1504\n",
      "Epoch 970/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 129701.5391 - val_loss: 28557.9551\n",
      "Epoch 971/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 130113.0078 - val_loss: 25392.8145\n",
      "Epoch 972/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 130917.8828 - val_loss: 32249.9375\n",
      "Epoch 973/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 134196.7500 - val_loss: 28923.3945\n",
      "Epoch 974/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 133805.7344 - val_loss: 29507.3203\n",
      "Epoch 975/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 130381.4922 - val_loss: 23966.3301\n",
      "Epoch 976/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 124242.3984 - val_loss: 27178.7324\n",
      "Epoch 977/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 129812.7344 - val_loss: 26981.0547\n",
      "Epoch 978/5000\n",
      "8/8 [==============================] - 7s 816ms/step - loss: 130585.6484 - val_loss: 28924.9512\n",
      "Epoch 979/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 133124.8594 - val_loss: 29766.9805\n",
      "Epoch 980/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 133470.1406 - val_loss: 28801.6465\n",
      "Epoch 981/5000\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 131013.9219 - val_loss: 28749.6973\n",
      "Epoch 982/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 132706.9062 - val_loss: 27938.6211\n",
      "Epoch 983/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 132815.0469 - val_loss: 33322.4727\n",
      "Epoch 984/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 140963.6406 - val_loss: 34408.6172\n",
      "Epoch 985/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 132209.9375 - val_loss: 39032.9258\n",
      "Epoch 986/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 129411.0469 - val_loss: 33528.3789\n",
      "Epoch 987/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 131785.3906 - val_loss: 27925.1309\n",
      "Epoch 988/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 136729.6719 - val_loss: 26018.5664\n",
      "Epoch 989/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 133081.1250 - val_loss: 25710.4551\n",
      "Epoch 990/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 124205.9219 - val_loss: 25237.8008\n",
      "Epoch 991/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 123248.0312 - val_loss: 27417.9336\n",
      "Epoch 992/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 127516.5781 - val_loss: 29029.3672\n",
      "Epoch 993/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 126992.7266 - val_loss: 25752.4883\n",
      "Epoch 994/5000\n",
      "8/8 [==============================] - 6s 809ms/step - loss: 128428.1719 - val_loss: 27142.7715\n",
      "Epoch 995/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 127953.8438 - val_loss: 26545.5078\n",
      "Epoch 996/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 124957.2422 - val_loss: 30250.1211\n",
      "Epoch 997/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 126295.7344 - val_loss: 25790.2285\n",
      "Epoch 998/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 124589.6641 - val_loss: 26492.4961\n",
      "Epoch 999/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 127413.8516 - val_loss: 30065.2148\n",
      "Epoch 1000/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 125937.5391 - val_loss: 25645.1504\n",
      "Epoch 1001/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 125948.8984 - val_loss: 26720.2383\n",
      "Epoch 1002/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 124921.7578 - val_loss: 29248.5684\n",
      "Epoch 1003/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 131104.4688 - val_loss: 25500.5625\n",
      "Epoch 1004/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 125508.1484 - val_loss: 24758.9824\n",
      "Epoch 1005/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 124830.8594 - val_loss: 28762.4629\n",
      "Epoch 1006/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 128528.9688 - val_loss: 25288.5996\n",
      "Epoch 1007/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 130277.3203 - val_loss: 26465.5762\n",
      "Epoch 1008/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 132081.1094 - val_loss: 24375.3223\n",
      "Epoch 1009/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 130259.4531 - val_loss: 28580.0684\n",
      "Epoch 1010/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 131458.3125 - val_loss: 26084.0742\n",
      "Epoch 1011/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 122051.5547 - val_loss: 29240.6016\n",
      "Epoch 1012/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 131303.0938 - val_loss: 29139.4160\n",
      "Epoch 1013/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 128147.9062 - val_loss: 30919.7773\n",
      "Epoch 1014/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 128612.7969 - val_loss: 27061.9160\n",
      "Epoch 1015/5000\n",
      "8/8 [==============================] - 7s 814ms/step - loss: 133995.5469 - val_loss: 29756.9551\n",
      "Epoch 1016/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 126750.7188 - val_loss: 33891.4258\n",
      "Epoch 1017/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 122968.1172 - val_loss: 27712.9043\n",
      "Epoch 1018/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 130838.1797 - val_loss: 25811.2988\n",
      "Epoch 1019/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 127275.4766 - val_loss: 31246.8828\n",
      "Epoch 1020/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 128641.4766 - val_loss: 24689.9922\n",
      "Epoch 1021/5000\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 131407.9062 - val_loss: 30090.3203\n",
      "Epoch 1022/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 130966.1250 - val_loss: 29712.8242\n",
      "Epoch 1023/5000\n",
      "8/8 [==============================] - 7s 899ms/step - loss: 134017.2969 - val_loss: 53014.1094\n",
      "Epoch 1024/5000\n",
      "8/8 [==============================] - 7s 838ms/step - loss: 143426.9375 - val_loss: 30607.0605\n",
      "Epoch 1025/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 139064.7188 - val_loss: 34189.8242\n",
      "Epoch 1026/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 135463.6406 - val_loss: 33885.0352\n",
      "Epoch 1027/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 135910.0469 - val_loss: 36121.9258\n",
      "Epoch 1028/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 133567.8906 - val_loss: 43269.4375\n",
      "Epoch 1029/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 135422.9688 - val_loss: 46216.5000\n",
      "Epoch 1030/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 131410.5625 - val_loss: 29457.2246\n",
      "Epoch 1031/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 125526.9062 - val_loss: 31142.2949\n",
      "Epoch 1032/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 128049.7969 - val_loss: 26130.4277\n",
      "Epoch 1033/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 125555.9297 - val_loss: 26373.5137\n",
      "Epoch 1034/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 125146.0078 - val_loss: 29092.4785\n",
      "Epoch 1035/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 789ms/step - loss: 125370.2812 - val_loss: 28350.2090\n",
      "Epoch 1036/5000\n",
      "8/8 [==============================] - 7s 813ms/step - loss: 128980.8203 - val_loss: 25155.7422\n",
      "Epoch 1037/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 127447.3281 - val_loss: 27150.6367\n",
      "Epoch 1038/5000\n",
      "8/8 [==============================] - 7s 838ms/step - loss: 128449.8984 - val_loss: 27203.2051\n",
      "Epoch 1039/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 133221.7969 - val_loss: 26898.5488\n",
      "Epoch 1040/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 125358.0859 - val_loss: 26534.9688\n",
      "Epoch 1041/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 127666.2266 - val_loss: 27435.6953\n",
      "Epoch 1042/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 129468.4922 - val_loss: 27781.0391\n",
      "Epoch 1043/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 129345.8281 - val_loss: 27091.7578\n",
      "Epoch 1044/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 131636.0625 - val_loss: 27782.2285\n",
      "Epoch 1045/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 131605.8750 - val_loss: 26391.3379\n",
      "Epoch 1046/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 125596.1250 - val_loss: 26378.9062\n",
      "Epoch 1047/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 123597.0234 - val_loss: 27832.9746\n",
      "Epoch 1048/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 124838.1172 - val_loss: 24878.9590\n",
      "Epoch 1049/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 124591.9844 - val_loss: 28476.1309\n",
      "Epoch 1050/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 132686.9531 - val_loss: 26214.3398\n",
      "Epoch 1051/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 128981.9922 - val_loss: 26699.2168\n",
      "Epoch 1052/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 132980.2656 - val_loss: 26995.9297\n",
      "Epoch 1053/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 125582.7812 - val_loss: 26186.9629\n",
      "Epoch 1054/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 130422.2344 - val_loss: 27368.6016\n",
      "Epoch 1055/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 130880.8984 - val_loss: 28821.8750\n",
      "Epoch 1056/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 129452.5938 - val_loss: 26574.6172\n",
      "Epoch 1057/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 125441.5234 - val_loss: 26224.2949\n",
      "Epoch 1058/5000\n",
      "8/8 [==============================] - 7s 889ms/step - loss: 125091.0859 - val_loss: 26039.2715\n",
      "Epoch 1059/5000\n",
      "8/8 [==============================] - 6s 768ms/step - loss: 125947.3203 - val_loss: 26394.3379\n",
      "Epoch 1060/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 119111.9609 - val_loss: 26252.7266\n",
      "Epoch 1061/5000\n",
      "8/8 [==============================] - 7s 875ms/step - loss: 124374.0391 - val_loss: 24649.1191\n",
      "Epoch 1062/5000\n",
      "8/8 [==============================] - 7s 873ms/step - loss: 123880.3828 - val_loss: 24728.3848\n",
      "Epoch 1063/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 125383.0547 - val_loss: 26842.8926\n",
      "Epoch 1064/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 128772.7734 - val_loss: 26992.5645\n",
      "Epoch 1065/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 128536.9453 - val_loss: 30587.5684\n",
      "Epoch 1066/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 128276.6406 - val_loss: 26403.3848\n",
      "Epoch 1067/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 134303.0938 - val_loss: 28413.7988\n",
      "Epoch 1068/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 130114.3672 - val_loss: 25376.5078\n",
      "Epoch 1069/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 130542.4297 - val_loss: 27774.7676\n",
      "Epoch 1070/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 134276.5156 - val_loss: 32323.7676\n",
      "Epoch 1071/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 132899.5781 - val_loss: 30043.2129\n",
      "Epoch 1072/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 126029.7109 - val_loss: 26202.7148\n",
      "Epoch 1073/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 129015.6328 - val_loss: 29332.5820\n",
      "Epoch 1074/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 136631.4219 - val_loss: 28916.7832\n",
      "Epoch 1075/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 132525.1719 - val_loss: 25754.2500\n",
      "Epoch 1076/5000\n",
      "8/8 [==============================] - 7s 814ms/step - loss: 126340.4531 - val_loss: 30432.6543\n",
      "Epoch 1077/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 136985.1562 - val_loss: 26371.3223\n",
      "Epoch 1078/5000\n",
      "8/8 [==============================] - 7s 823ms/step - loss: 128805.0078 - val_loss: 25664.2207\n",
      "Epoch 1079/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 130150.2344 - val_loss: 32165.8340\n",
      "Epoch 1080/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 139049.8125 - val_loss: 28867.0312\n",
      "Epoch 1081/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 129451.0859 - val_loss: 24234.7285\n",
      "Epoch 1082/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 127463.9297 - val_loss: 28149.0703\n",
      "Epoch 1083/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 134194.5156 - val_loss: 30969.7871\n",
      "Epoch 1084/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 130379.1953 - val_loss: 27555.2207\n",
      "Epoch 1085/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 123963.9453 - val_loss: 28886.5117\n",
      "Epoch 1086/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 130375.2422 - val_loss: 27884.1738\n",
      "Epoch 1087/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 127161.5078 - val_loss: 26455.1855\n",
      "Epoch 1088/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 129297.3984 - val_loss: 25764.1777\n",
      "Epoch 1089/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 122585.2188 - val_loss: 25499.3633\n",
      "Epoch 1090/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 124113.9844 - val_loss: 27848.1289\n",
      "Epoch 1091/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 123695.9531 - val_loss: 27244.2441\n",
      "Epoch 1092/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 131908.9219 - val_loss: 25923.7793\n",
      "Epoch 1093/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 125332.8984 - val_loss: 26268.1367\n",
      "Epoch 1094/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 124132.1016 - val_loss: 25508.8926\n",
      "Epoch 1095/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 131849.4844 - val_loss: 28526.5586\n",
      "Epoch 1096/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 132250.1719 - val_loss: 27848.2617\n",
      "Epoch 1097/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 126513.9297 - val_loss: 28770.9863\n",
      "Epoch 1098/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 134788.1406 - val_loss: 30612.2148\n",
      "Epoch 1099/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 124542.3359 - val_loss: 26636.8535\n",
      "Epoch 1100/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 125648.2188 - val_loss: 28894.8379\n",
      "Epoch 1101/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 125769.9766 - val_loss: 25868.9609\n",
      "Epoch 1102/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 122924.2109 - val_loss: 23647.5547\n",
      "Epoch 1103/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 124977.5078 - val_loss: 24932.1621\n",
      "Epoch 1104/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 126670.2422 - val_loss: 27606.1367\n",
      "Epoch 1105/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 129664.5938 - val_loss: 28204.0547\n",
      "Epoch 1106/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 124193.6328 - val_loss: 32348.4297\n",
      "Epoch 1107/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 123811.3438 - val_loss: 26554.3086\n",
      "Epoch 1108/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 7s 827ms/step - loss: 126906.9062 - val_loss: 29566.5137\n",
      "Epoch 1109/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 131297.1719 - val_loss: 26232.9160\n",
      "Epoch 1110/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 121361.1562 - val_loss: 27529.6699\n",
      "Epoch 1111/5000\n",
      "8/8 [==============================] - 6s 810ms/step - loss: 129340.9609 - val_loss: 33552.2656\n",
      "Epoch 1112/5000\n",
      "8/8 [==============================] - 6s 810ms/step - loss: 127123.9844 - val_loss: 28691.8008\n",
      "Epoch 1113/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 126655.8203 - val_loss: 28556.6582\n",
      "Epoch 1114/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 130515.1719 - val_loss: 26491.5449\n",
      "Epoch 1115/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 122264.1016 - val_loss: 31607.8457\n",
      "Epoch 1116/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 122947.2188 - val_loss: 27546.6289\n",
      "Epoch 1117/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 118038.0312 - val_loss: 30056.8926\n",
      "Epoch 1118/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 122259.2109 - val_loss: 26074.4082\n",
      "Epoch 1119/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 120690.0000 - val_loss: 23606.0332\n",
      "Epoch 1120/5000\n",
      "8/8 [==============================] - 7s 815ms/step - loss: 113788.8359 - val_loss: 28150.4102\n",
      "Epoch 1121/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 121680.9531 - val_loss: 25356.4648\n",
      "Epoch 1122/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 124056.3828 - val_loss: 27315.1562\n",
      "Epoch 1123/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 119768.3828 - val_loss: 29647.4453\n",
      "Epoch 1124/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 115730.0469 - val_loss: 27415.7832\n",
      "Epoch 1125/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 119574.1484 - val_loss: 35972.5430\n",
      "Epoch 1126/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 122392.7812 - val_loss: 31143.6836\n",
      "Epoch 1127/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 125101.7031 - val_loss: 25061.6113\n",
      "Epoch 1128/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 121062.1172 - val_loss: 27597.5508\n",
      "Epoch 1129/5000\n",
      "8/8 [==============================] - 6s 809ms/step - loss: 124047.7031 - val_loss: 26531.4668\n",
      "Epoch 1130/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 121937.7969 - val_loss: 26187.7402\n",
      "Epoch 1131/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 121384.5469 - val_loss: 28851.1660\n",
      "Epoch 1132/5000\n",
      "8/8 [==============================] - 7s 817ms/step - loss: 127260.0781 - val_loss: 26282.2539\n",
      "Epoch 1133/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 123966.2812 - val_loss: 25145.7305\n",
      "Epoch 1134/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 119997.5312 - val_loss: 27966.8496\n",
      "Epoch 1135/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 129149.9922 - val_loss: 29334.8711\n",
      "Epoch 1136/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 129117.1328 - val_loss: 29023.8457\n",
      "Epoch 1137/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 121840.3984 - val_loss: 28598.8340\n",
      "Epoch 1138/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 126012.5703 - val_loss: 33710.6016\n",
      "Epoch 1139/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 133263.3594 - val_loss: 25823.2012\n",
      "Epoch 1140/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 124004.9531 - val_loss: 31380.7559\n",
      "Epoch 1141/5000\n",
      "8/8 [==============================] - 6s 769ms/step - loss: 128856.2891 - val_loss: 30983.4238\n",
      "Epoch 1142/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 123678.5312 - val_loss: 25846.9785\n",
      "Epoch 1143/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 124484.9688 - val_loss: 26752.3379\n",
      "Epoch 1144/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 122117.9922 - val_loss: 28838.8633\n",
      "Epoch 1145/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 132001.6562 - val_loss: 28523.9668\n",
      "Epoch 1146/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 121953.3359 - val_loss: 28951.7129\n",
      "Epoch 1147/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 134453.0781 - val_loss: 28728.2539\n",
      "Epoch 1148/5000\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 127399.2500 - val_loss: 25833.9805\n",
      "Epoch 1149/5000\n",
      "8/8 [==============================] - 6s 810ms/step - loss: 126270.1641 - val_loss: 28583.5742\n",
      "Epoch 1150/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 133914.5938 - val_loss: 29560.3418\n",
      "Epoch 1151/5000\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 132463.9531 - val_loss: 28332.5332\n",
      "Epoch 1152/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 132363.8281 - val_loss: 30632.8047\n",
      "Epoch 1153/5000\n",
      "8/8 [==============================] - 7s 815ms/step - loss: 130892.7344 - val_loss: 27212.9180\n",
      "Epoch 1154/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 130268.1250 - val_loss: 26323.4512\n",
      "Epoch 1155/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 126240.8438 - val_loss: 26961.7617\n",
      "Epoch 1156/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 125867.6641 - val_loss: 25372.7520\n",
      "Epoch 1157/5000\n",
      "8/8 [==============================] - 7s 824ms/step - loss: 132549.4531 - val_loss: 28312.0195\n",
      "Epoch 1158/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 123766.1484 - val_loss: 26557.2676\n",
      "Epoch 1159/5000\n",
      "8/8 [==============================] - 6s 810ms/step - loss: 127530.1172 - val_loss: 27443.6621\n",
      "Epoch 1160/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 123244.9766 - val_loss: 33244.8555\n",
      "Epoch 1161/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 120344.5000 - val_loss: 30724.3008\n",
      "Epoch 1162/5000\n",
      "8/8 [==============================] - 7s 816ms/step - loss: 124280.2031 - val_loss: 29504.5352\n",
      "Epoch 1163/5000\n",
      "8/8 [==============================] - 7s 818ms/step - loss: 122757.7188 - val_loss: 30438.0938\n",
      "Epoch 1164/5000\n",
      "8/8 [==============================] - 7s 818ms/step - loss: 115938.8047 - val_loss: 26164.7832\n",
      "Epoch 1165/5000\n",
      "8/8 [==============================] - 7s 817ms/step - loss: 112818.2344 - val_loss: 25699.3359\n",
      "Epoch 1166/5000\n",
      "8/8 [==============================] - 7s 813ms/step - loss: 122992.4297 - val_loss: 25443.3555\n",
      "Epoch 1167/5000\n",
      "8/8 [==============================] - 7s 823ms/step - loss: 124813.2500 - val_loss: 24658.3164\n",
      "Epoch 1168/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 119040.9688 - val_loss: 24042.3242\n",
      "Epoch 1169/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 116467.6484 - val_loss: 25746.5312\n",
      "Epoch 1170/5000\n",
      "8/8 [==============================] - 6s 768ms/step - loss: 123389.7891 - val_loss: 26310.7676\n",
      "Epoch 1171/5000\n",
      "8/8 [==============================] - 7s 820ms/step - loss: 122697.0312 - val_loss: 24443.8848\n",
      "Epoch 1172/5000\n",
      "8/8 [==============================] - 7s 822ms/step - loss: 122607.9609 - val_loss: 28529.5000\n",
      "Epoch 1173/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 122376.2656 - val_loss: 27963.9355\n",
      "Epoch 1174/5000\n",
      "8/8 [==============================] - 7s 826ms/step - loss: 126878.2812 - val_loss: 26866.2129\n",
      "Epoch 1175/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 127091.6016 - val_loss: 26170.9707\n",
      "Epoch 1176/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 126177.0234 - val_loss: 28634.4355\n",
      "Epoch 1177/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 128294.0391 - val_loss: 25273.9375\n",
      "Epoch 1178/5000\n",
      "8/8 [==============================] - 7s 842ms/step - loss: 127012.4844 - val_loss: 42006.3281\n",
      "Epoch 1179/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 128091.3594 - val_loss: 29759.9785\n",
      "Epoch 1180/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 131771.7969 - val_loss: 26803.9160\n",
      "Epoch 1181/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 787ms/step - loss: 127047.4453 - val_loss: 28508.6523\n",
      "Epoch 1182/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 127005.5000 - val_loss: 37783.8008\n",
      "Epoch 1183/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 127341.5156 - val_loss: 26085.2520\n",
      "Epoch 1184/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 118514.5781 - val_loss: 28376.7910\n",
      "Epoch 1185/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 129827.5234 - val_loss: 29597.1660\n",
      "Epoch 1186/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 129057.6016 - val_loss: 27930.0078\n",
      "Epoch 1187/5000\n",
      "8/8 [==============================] - 7s 829ms/step - loss: 122704.9922 - val_loss: 24517.1152\n",
      "Epoch 1188/5000\n",
      "8/8 [==============================] - 7s 890ms/step - loss: 127366.3828 - val_loss: 31413.7441\n",
      "Epoch 1189/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 130422.6484 - val_loss: 27810.5000\n",
      "Epoch 1190/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 126323.1562 - val_loss: 23663.6309\n",
      "Epoch 1191/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 135940.0781 - val_loss: 29600.1660\n",
      "Epoch 1192/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 129518.5000 - val_loss: 27162.7520\n",
      "Epoch 1193/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 134030.7031 - val_loss: 26275.7871\n",
      "Epoch 1194/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 124946.7188 - val_loss: 28683.3730\n",
      "Epoch 1195/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 130560.8516 - val_loss: 30604.1641\n",
      "Epoch 1196/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 139997.3125 - val_loss: 29175.0000\n",
      "Epoch 1197/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 133391.5938 - val_loss: 29577.6875\n",
      "Epoch 1198/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 129351.6641 - val_loss: 25714.0312\n",
      "Epoch 1199/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 128499.4297 - val_loss: 26180.2441\n",
      "Epoch 1200/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 127075.2109 - val_loss: 30845.1152\n",
      "Epoch 1201/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 133902.1250 - val_loss: 27469.3027\n",
      "Epoch 1202/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 130152.1562 - val_loss: 27726.1895\n",
      "Epoch 1203/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 129779.2891 - val_loss: 33900.8828\n",
      "Epoch 1204/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 138032.5469 - val_loss: 27259.5527\n",
      "Epoch 1205/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 126482.2812 - val_loss: 28854.7910\n",
      "Epoch 1206/5000\n",
      "8/8 [==============================] - 6s 769ms/step - loss: 123711.9531 - val_loss: 30808.1055\n",
      "Epoch 1207/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 132156.1094 - val_loss: 29917.1582\n",
      "Epoch 1208/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 128477.8984 - val_loss: 27631.6016\n",
      "Epoch 1209/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 128825.1953 - val_loss: 26064.1348\n",
      "Epoch 1210/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 126646.3672 - val_loss: 27969.1465\n",
      "Epoch 1211/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 130156.6094 - val_loss: 26372.0957\n",
      "Epoch 1212/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 128617.9531 - val_loss: 26821.1074\n",
      "Epoch 1213/5000\n",
      "8/8 [==============================] - 7s 827ms/step - loss: 131042.8750 - val_loss: 30349.3457\n",
      "Epoch 1214/5000\n",
      "8/8 [==============================] - 7s 823ms/step - loss: 130668.0547 - val_loss: 27420.2617\n",
      "Epoch 1215/5000\n",
      "8/8 [==============================] - 7s 813ms/step - loss: 135527.0469 - val_loss: 28581.5098\n",
      "Epoch 1216/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 131285.5625 - val_loss: 28601.6934\n",
      "Epoch 1217/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 133338.8125 - val_loss: 29309.4668\n",
      "Epoch 1218/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 132260.7656 - val_loss: 26820.4336\n",
      "Epoch 1219/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 126017.3750 - val_loss: 27271.9004\n",
      "Epoch 1220/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 127161.4844 - val_loss: 27980.6348\n",
      "Epoch 1221/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 130991.2656 - val_loss: 26428.7207\n",
      "Epoch 1222/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 124882.2812 - val_loss: 26879.4551\n",
      "Epoch 1223/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 130237.4062 - val_loss: 27730.5137\n",
      "Epoch 1224/5000\n",
      "8/8 [==============================] - 6s 769ms/step - loss: 133264.1250 - val_loss: 25646.2402\n",
      "Epoch 1225/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 131316.5312 - val_loss: 29135.6348\n",
      "Epoch 1226/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 127366.0000 - val_loss: 29067.7754\n",
      "Epoch 1227/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 128724.9297 - val_loss: 25334.3770\n",
      "Epoch 1228/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 122457.5547 - val_loss: 26802.3301\n",
      "Epoch 1229/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 124272.7656 - val_loss: 26566.6895\n",
      "Epoch 1230/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 134234.6719 - val_loss: 31668.3770\n",
      "Epoch 1231/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 127670.2188 - val_loss: 28882.5547\n",
      "Epoch 1232/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 124674.5078 - val_loss: 32992.6875\n",
      "Epoch 1233/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 125589.2422 - val_loss: 27418.6250\n",
      "Epoch 1234/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 131803.0938 - val_loss: 28108.6250\n",
      "Epoch 1235/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 134277.7031 - val_loss: 28062.9570\n",
      "Epoch 1236/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 128950.4062 - val_loss: 31962.7148\n",
      "Epoch 1237/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 126562.3984 - val_loss: 26956.4668\n",
      "Epoch 1238/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 132106.3125 - val_loss: 28425.9316\n",
      "Epoch 1239/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 132259.6562 - val_loss: 28429.0020\n",
      "Epoch 1240/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 131103.4844 - val_loss: 30840.7324\n",
      "Epoch 1241/5000\n",
      "8/8 [==============================] - 6s 769ms/step - loss: 130310.7969 - val_loss: 27959.0039\n",
      "Epoch 1242/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 130905.9609 - val_loss: 29399.8867\n",
      "Epoch 1243/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 138407.7969 - val_loss: 26472.6953\n",
      "Epoch 1244/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 150858.6094 - val_loss: 28261.8574\n",
      "Epoch 1245/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 141302.1875 - val_loss: 29259.5586\n",
      "Epoch 1246/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 137831.3906 - val_loss: 26008.9922\n",
      "Epoch 1247/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 130006.0000 - val_loss: 31615.6660\n",
      "Epoch 1248/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 137563.5469 - val_loss: 30622.6914\n",
      "Epoch 1249/5000\n",
      "8/8 [==============================] - 7s 908ms/step - loss: 135400.7188 - val_loss: 29019.5312\n",
      "Epoch 1250/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 137213.4844 - val_loss: 28170.2832\n",
      "Epoch 1251/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 133908.3750 - val_loss: 27534.3750\n",
      "Epoch 1252/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 129603.5938 - val_loss: 25284.6113\n",
      "Epoch 1253/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 131718.7500 - val_loss: 26740.9082\n",
      "Epoch 1254/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 783ms/step - loss: 128421.7812 - val_loss: 26920.7441\n",
      "Epoch 1255/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 138674.2656 - val_loss: 24949.1953\n",
      "Epoch 1256/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 123168.3672 - val_loss: 24513.9121\n",
      "Epoch 1257/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 138801.1094 - val_loss: 30484.8438\n",
      "Epoch 1258/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 132844.7031 - val_loss: 27210.9258\n",
      "Epoch 1259/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 130945.9062 - val_loss: 28459.5215\n",
      "Epoch 1260/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 136262.4531 - val_loss: 26035.4375\n",
      "Epoch 1261/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 130379.0703 - val_loss: 27140.8145\n",
      "Epoch 1262/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 131030.3984 - val_loss: 31680.3672\n",
      "Epoch 1263/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 136691.5312 - val_loss: 31528.0879\n",
      "Epoch 1264/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 135704.4219 - val_loss: 27932.6660\n",
      "Epoch 1265/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 133798.4844 - val_loss: 30617.5078\n",
      "Epoch 1266/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 133611.7188 - val_loss: 32642.9492\n",
      "Epoch 1267/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 138419.2344 - val_loss: 31205.1367\n",
      "Epoch 1268/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 137493.0781 - val_loss: 29473.5840\n",
      "Epoch 1269/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 139958.1406 - val_loss: 28868.9746\n",
      "Epoch 1270/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 136610.3438 - val_loss: 32034.6953\n",
      "Epoch 1271/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 134153.5781 - val_loss: 27108.1465\n",
      "Epoch 1272/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 129195.1250 - val_loss: 26702.4902\n",
      "Epoch 1273/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 130134.6328 - val_loss: 28097.6562\n",
      "Epoch 1274/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 131536.5000 - val_loss: 27798.1699\n",
      "Epoch 1275/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 127873.9297 - val_loss: 27541.0410\n",
      "Epoch 1276/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 135976.6875 - val_loss: 29844.4336\n",
      "Epoch 1277/5000\n",
      "8/8 [==============================] - 7s 823ms/step - loss: 134780.9375 - val_loss: 28668.4785\n",
      "Epoch 1278/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 134620.7344 - val_loss: 29386.7461\n",
      "Epoch 1279/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 134317.9219 - val_loss: 27959.1875\n",
      "Epoch 1280/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 135975.7969 - val_loss: 29913.7891\n",
      "Epoch 1281/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 132677.1406 - val_loss: 29514.0332\n",
      "Epoch 1282/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 130040.0781 - val_loss: 28590.3105\n",
      "Epoch 1283/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 139847.2969 - val_loss: 28336.5352\n",
      "Epoch 1284/5000\n",
      "8/8 [==============================] - 7s 874ms/step - loss: 138340.3281 - val_loss: 28956.5449\n",
      "Epoch 1285/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 132277.4531 - val_loss: 25752.4688\n",
      "Epoch 1286/5000\n",
      "8/8 [==============================] - 6s 766ms/step - loss: 132059.0781 - val_loss: 29458.4316\n",
      "Epoch 1287/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 140360.3906 - val_loss: 26990.8418\n",
      "Epoch 1288/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 140242.0625 - val_loss: 28077.5723\n",
      "Epoch 1289/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 128382.7266 - val_loss: 24893.9375\n",
      "Epoch 1290/5000\n",
      "8/8 [==============================] - 9s 1s/step - loss: 129828.4297 - val_loss: 29638.5508\n",
      "Epoch 1291/5000\n",
      "8/8 [==============================] - 7s 849ms/step - loss: 138586.1406 - val_loss: 28158.7871\n",
      "Epoch 1292/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 130212.8672 - val_loss: 25753.8223\n",
      "Epoch 1293/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 127182.0547 - val_loss: 32568.0176\n",
      "Epoch 1294/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 134124.3906 - val_loss: 29362.2910\n",
      "Epoch 1295/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 134445.4062 - val_loss: 27335.0742\n",
      "Epoch 1296/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 129692.0391 - val_loss: 27832.3672\n",
      "Epoch 1297/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 130776.6641 - val_loss: 27340.3359\n",
      "Epoch 1298/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 128436.6406 - val_loss: 25019.9590\n",
      "Epoch 1299/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 127671.2891 - val_loss: 26727.2812\n",
      "Epoch 1300/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 129745.3984 - val_loss: 28116.9629\n",
      "Epoch 1301/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 130179.8906 - val_loss: 27956.2266\n",
      "Epoch 1302/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 135435.3281 - val_loss: 33471.7109\n",
      "Epoch 1303/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 137145.0781 - val_loss: 29423.1016\n",
      "Epoch 1304/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 133205.9531 - val_loss: 30905.7051\n",
      "Epoch 1305/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 131231.8594 - val_loss: 26743.8555\n",
      "Epoch 1306/5000\n",
      "8/8 [==============================] - 6s 769ms/step - loss: 128038.0703 - val_loss: 27534.7539\n",
      "Epoch 1307/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 135993.4688 - val_loss: 27443.5195\n",
      "Epoch 1308/5000\n",
      "8/8 [==============================] - 6s 764ms/step - loss: 131593.9844 - val_loss: 27210.4395\n",
      "Epoch 1309/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 129265.1016 - val_loss: 29858.4551\n",
      "Epoch 1310/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 132014.8281 - val_loss: 26641.1816\n",
      "Epoch 1311/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 133173.7344 - val_loss: 27051.8047\n",
      "Epoch 1312/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 131796.5156 - val_loss: 28197.3828\n",
      "Epoch 1313/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 129186.6406 - val_loss: 34609.3867\n",
      "Epoch 1314/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 129992.0703 - val_loss: 25477.9551\n",
      "Epoch 1315/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 129735.3359 - val_loss: 35432.3398\n",
      "Epoch 1316/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 130938.8828 - val_loss: 28487.8965\n",
      "Epoch 1317/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 127106.0547 - val_loss: 26155.8320\n",
      "Epoch 1318/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 128887.0000 - val_loss: 26038.6582\n",
      "Epoch 1319/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 124835.0469 - val_loss: 28525.5703\n",
      "Epoch 1320/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 133152.2031 - val_loss: 29002.4453\n",
      "Epoch 1321/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 131417.1406 - val_loss: 31269.4453\n",
      "Epoch 1322/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 134184.9531 - val_loss: 26830.0664\n",
      "Epoch 1323/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 136664.0156 - val_loss: 33099.1250\n",
      "Epoch 1324/5000\n",
      "8/8 [==============================] - 7s 882ms/step - loss: 138680.9688 - val_loss: 28765.0449\n",
      "Epoch 1325/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 129689.8281 - val_loss: 47245.1836\n",
      "Epoch 1326/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 129847.6953 - val_loss: 32864.9414\n",
      "Epoch 1327/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 781ms/step - loss: 127398.7578 - val_loss: 30081.0742\n",
      "Epoch 1328/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 129927.3281 - val_loss: 26564.6660\n",
      "Epoch 1329/5000\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 123851.6172 - val_loss: 27893.3398\n",
      "Epoch 1330/5000\n",
      "8/8 [==============================] - 7s 814ms/step - loss: 126345.3984 - val_loss: 26034.3867\n",
      "Epoch 1331/5000\n",
      "8/8 [==============================] - 7s 858ms/step - loss: 126668.5000 - val_loss: 27028.8184\n",
      "Epoch 1332/5000\n",
      "8/8 [==============================] - 7s 842ms/step - loss: 131530.6562 - val_loss: 27686.2734\n",
      "Epoch 1333/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 128550.3438 - val_loss: 26892.1113\n",
      "Epoch 1334/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 126736.8906 - val_loss: 29673.2109\n",
      "Epoch 1335/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 130686.5312 - val_loss: 29314.4004\n",
      "Epoch 1336/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 141897.8281 - val_loss: 27430.8945\n",
      "Epoch 1337/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 126309.2344 - val_loss: 25940.1602\n",
      "Epoch 1338/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 124924.8672 - val_loss: 26313.1230\n",
      "Epoch 1339/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 124089.8750 - val_loss: 25904.0410\n",
      "Epoch 1340/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 128557.6797 - val_loss: 27748.0605\n",
      "Epoch 1341/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 122602.8984 - val_loss: 26755.6387\n",
      "Epoch 1342/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 127088.7031 - val_loss: 27598.5938\n",
      "Epoch 1343/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 133511.1250 - val_loss: 28569.7715\n",
      "Epoch 1344/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 129595.3359 - val_loss: 34003.0781\n",
      "Epoch 1345/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 141303.2031 - val_loss: 38724.9336\n",
      "Epoch 1346/5000\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 138920.3281 - val_loss: 30165.9023\n",
      "Epoch 1347/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 131656.1094 - val_loss: 30193.8867\n",
      "Epoch 1348/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 145698.5781 - val_loss: 27542.1133\n",
      "Epoch 1349/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 140014.6719 - val_loss: 27530.8867\n",
      "Epoch 1350/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 154400.4219 - val_loss: 29847.2871\n",
      "Epoch 1351/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 142495.2344 - val_loss: 31686.4062\n",
      "Epoch 1352/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 138422.7656 - val_loss: 29518.0410\n",
      "Epoch 1353/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 146055.8906 - val_loss: 27093.7168\n",
      "Epoch 1354/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 134021.9219 - val_loss: 35321.6211\n",
      "Epoch 1355/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 141907.7812 - val_loss: 30091.7520\n",
      "Epoch 1356/5000\n",
      "8/8 [==============================] - 6s 771ms/step - loss: 140454.7188 - val_loss: 30491.3574\n",
      "Epoch 1357/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 142158.4219 - val_loss: 28019.4297\n",
      "Epoch 1358/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 146205.4688 - val_loss: 30226.0293\n",
      "Epoch 1359/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 144440.8438 - val_loss: 29049.2793\n",
      "Epoch 1360/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 145352.0156 - val_loss: 29877.2578\n",
      "Epoch 1361/5000\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 133662.2656 - val_loss: 26146.7500\n",
      "Epoch 1362/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 132192.7812 - val_loss: 26022.5391\n",
      "Epoch 1363/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 125950.4766 - val_loss: 27292.9141\n",
      "Epoch 1364/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 126207.2969 - val_loss: 28832.8848\n",
      "Epoch 1365/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 137761.6562 - val_loss: 26688.3203\n",
      "Epoch 1366/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 136088.3281 - val_loss: 25208.4961\n",
      "Epoch 1367/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 126906.6328 - val_loss: 23995.4707\n",
      "Epoch 1368/5000\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 127034.0391 - val_loss: 26581.9199\n",
      "Epoch 1369/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 131182.0000 - val_loss: 27370.5254\n",
      "Epoch 1370/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 137703.5781 - val_loss: 29691.4102\n",
      "Epoch 1371/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 150102.2969 - val_loss: 25453.1270\n",
      "Epoch 1372/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 131544.3750 - val_loss: 27088.9160\n",
      "Epoch 1373/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 131212.5156 - val_loss: 26574.6172\n",
      "Epoch 1374/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 130927.8906 - val_loss: 24498.8398\n",
      "Epoch 1375/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 122414.2031 - val_loss: 23533.7910\n",
      "Epoch 1376/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 124295.5156 - val_loss: 27830.6602\n",
      "Epoch 1377/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 124165.3672 - val_loss: 27403.8379\n",
      "Epoch 1378/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 124051.9688 - val_loss: 27577.2227\n",
      "Epoch 1379/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 128780.1328 - val_loss: 26733.8320\n",
      "Epoch 1380/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 133771.3125 - val_loss: 26932.1875\n",
      "Epoch 1381/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 132706.8594 - val_loss: 26980.3301\n",
      "Epoch 1382/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 135088.5000 - val_loss: 26079.0430\n",
      "Epoch 1383/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 140586.5625 - val_loss: 27406.9961\n",
      "Epoch 1384/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 139468.9844 - val_loss: 27634.9258\n",
      "Epoch 1385/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 145386.2656 - val_loss: 32781.3945\n",
      "Epoch 1386/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 139796.5781 - val_loss: 28912.5293\n",
      "Epoch 1387/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 135596.6875 - val_loss: 27923.0703\n",
      "Epoch 1388/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 144861.3281 - val_loss: 35059.4570\n",
      "Epoch 1389/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 133999.1250 - val_loss: 34971.3906\n",
      "Epoch 1390/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 132109.0000 - val_loss: 30335.5098\n",
      "Epoch 1391/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 149234.1719 - val_loss: 28055.5332\n",
      "Epoch 1392/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 131570.2188 - val_loss: 24341.1953\n",
      "Epoch 1393/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 126991.7734 - val_loss: 26128.4199\n",
      "Epoch 1394/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 126371.0156 - val_loss: 26497.3652\n",
      "Epoch 1395/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 130591.3594 - val_loss: 27068.0508\n",
      "Epoch 1396/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 130041.2812 - val_loss: 27578.6582\n",
      "Epoch 1397/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 130878.3203 - val_loss: 26187.6602\n",
      "Epoch 1398/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 131589.4844 - val_loss: 25190.5840\n",
      "Epoch 1399/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 123622.5078 - val_loss: 26045.8984\n",
      "Epoch 1400/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 809ms/step - loss: 125223.8750 - val_loss: 24838.1738\n",
      "Epoch 1401/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 127842.8828 - val_loss: 27108.4453\n",
      "Epoch 1402/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 131106.9375 - val_loss: 26111.9551\n",
      "Epoch 1403/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 125342.0000 - val_loss: 28138.2012\n",
      "Epoch 1404/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 126414.3516 - val_loss: 26076.1680\n",
      "Epoch 1405/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 127569.1094 - val_loss: 28621.2910\n",
      "Epoch 1406/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 131134.0938 - val_loss: 28300.9707\n",
      "Epoch 1407/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 131493.0156 - val_loss: 26408.0449\n",
      "Epoch 1408/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 131833.4375 - val_loss: 26564.4629\n",
      "Epoch 1409/5000\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 124510.2031 - val_loss: 26403.1504\n",
      "Epoch 1410/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 131958.4531 - val_loss: 26382.6562\n",
      "Epoch 1411/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 128781.7578 - val_loss: 26964.0078\n",
      "Epoch 1412/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 125034.4453 - val_loss: 23277.0938\n",
      "Epoch 1413/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 122013.6406 - val_loss: 25741.8105\n",
      "Epoch 1414/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 125428.6484 - val_loss: 26646.3340\n",
      "Epoch 1415/5000\n",
      "8/8 [==============================] - 7s 821ms/step - loss: 129845.0547 - val_loss: 24432.9766\n",
      "Epoch 1416/5000\n",
      "8/8 [==============================] - 7s 851ms/step - loss: 127511.7344 - val_loss: 24431.7207\n",
      "Epoch 1417/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 127744.5859 - val_loss: 28480.3301\n",
      "Epoch 1418/5000\n",
      "8/8 [==============================] - 7s 843ms/step - loss: 125339.5703 - val_loss: 28776.6465\n",
      "Epoch 1419/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 127990.1797 - val_loss: 26935.4707\n",
      "Epoch 1420/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 130399.3984 - val_loss: 30939.0684\n",
      "Epoch 1421/5000\n",
      "8/8 [==============================] - 6s 768ms/step - loss: 134193.8281 - val_loss: 36384.1836\n",
      "Epoch 1422/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 124827.3594 - val_loss: 41508.9961\n",
      "Epoch 1423/5000\n",
      "8/8 [==============================] - 6s 771ms/step - loss: 128736.3438 - val_loss: 25659.0039\n",
      "Epoch 1424/5000\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 118254.2109 - val_loss: 27783.4922\n",
      "Epoch 1425/5000\n",
      "8/8 [==============================] - 6s 771ms/step - loss: 126705.4609 - val_loss: 26443.8340\n",
      "Epoch 1426/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 130751.6328 - val_loss: 27968.4336\n",
      "Epoch 1427/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 126691.4453 - val_loss: 27974.6914\n",
      "Epoch 1428/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 128041.8750 - val_loss: 30459.1172\n",
      "Epoch 1429/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 125369.2500 - val_loss: 27466.8711\n",
      "Epoch 1430/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 127764.2266 - val_loss: 25467.0859\n",
      "Epoch 1431/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 132223.3906 - val_loss: 28313.3867\n",
      "Epoch 1432/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 129770.3750 - val_loss: 36849.8047\n",
      "Epoch 1433/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 132177.5156 - val_loss: 29929.8105\n",
      "Epoch 1434/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 126581.8828 - val_loss: 29036.5645\n",
      "Epoch 1435/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 125990.1328 - val_loss: 28872.4668\n",
      "Epoch 1436/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 131342.5625 - val_loss: 27371.6816\n",
      "Epoch 1437/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 127402.3594 - val_loss: 28700.7812\n",
      "Epoch 1438/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 129213.5547 - val_loss: 26021.6465\n",
      "Epoch 1439/5000\n",
      "8/8 [==============================] - 7s 837ms/step - loss: 131437.1094 - val_loss: 31369.6035\n",
      "Epoch 1440/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 128154.2031 - val_loss: 28637.7578\n",
      "Epoch 1441/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 128027.6016 - val_loss: 27707.9570\n",
      "Epoch 1442/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 131344.1094 - val_loss: 32666.1836\n",
      "Epoch 1443/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 128439.6484 - val_loss: 28636.4180\n",
      "Epoch 1444/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 128909.7734 - val_loss: 26370.8965\n",
      "Epoch 1445/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 131820.8438 - val_loss: 30048.9297\n",
      "Epoch 1446/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 139830.4375 - val_loss: 28168.6680\n",
      "Epoch 1447/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 129944.8750 - val_loss: 27745.3320\n",
      "Epoch 1448/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 125890.2656 - val_loss: 23662.3242\n",
      "Epoch 1449/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 126699.5469 - val_loss: 30204.0703\n",
      "Epoch 1450/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 124591.9062 - val_loss: 23908.6074\n",
      "Epoch 1451/5000\n",
      "8/8 [==============================] - 7s 902ms/step - loss: 120106.5938 - val_loss: 27396.7676\n",
      "Epoch 1452/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 121887.4453 - val_loss: 26213.8301\n",
      "Epoch 1453/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 124949.6484 - val_loss: 26761.5137\n",
      "Epoch 1454/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 128903.2188 - val_loss: 28358.4297\n",
      "Epoch 1455/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 130131.3203 - val_loss: 30044.9668\n",
      "Epoch 1456/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 131157.9375 - val_loss: 23281.1250\n",
      "Epoch 1457/5000\n",
      "8/8 [==============================] - 7s 821ms/step - loss: 123050.1641 - val_loss: 26813.8457\n",
      "Epoch 1458/5000\n",
      "8/8 [==============================] - 7s 895ms/step - loss: 126977.0703 - val_loss: 27797.9961\n",
      "Epoch 1459/5000\n",
      "8/8 [==============================] - 7s 863ms/step - loss: 139041.7031 - val_loss: 28764.5664\n",
      "Epoch 1460/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 128350.6406 - val_loss: 28185.1113\n",
      "Epoch 1461/5000\n",
      "8/8 [==============================] - 7s 820ms/step - loss: 126922.9609 - val_loss: 27280.4492\n",
      "Epoch 1462/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 123352.7422 - val_loss: 26614.5801\n",
      "Epoch 1463/5000\n",
      "8/8 [==============================] - 7s 867ms/step - loss: 122505.9297 - val_loss: 28368.7852\n",
      "Epoch 1464/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 122209.3359 - val_loss: 26883.6953\n",
      "Epoch 1465/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 126722.8047 - val_loss: 28143.7402\n",
      "Epoch 1466/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 124841.9062 - val_loss: 25180.2715\n",
      "Epoch 1467/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 119241.4297 - val_loss: 24687.5840\n",
      "Epoch 1468/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 121025.5469 - val_loss: 27193.7246\n",
      "Epoch 1469/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 124260.9141 - val_loss: 24612.9199\n",
      "Epoch 1470/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 125165.6641 - val_loss: 27597.5625\n",
      "Epoch 1471/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 131636.0469 - val_loss: 29597.1211\n",
      "Epoch 1472/5000\n",
      "8/8 [==============================] - 7s 816ms/step - loss: 133779.5938 - val_loss: 26658.7695\n",
      "Epoch 1473/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 797ms/step - loss: 130563.1172 - val_loss: 26650.2363\n",
      "Epoch 1474/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 129236.7578 - val_loss: 28241.7461\n",
      "Epoch 1475/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 128851.8594 - val_loss: 28914.1523\n",
      "Epoch 1476/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 125793.5078 - val_loss: 31549.4883\n",
      "Epoch 1477/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 125631.1562 - val_loss: 26190.7305\n",
      "Epoch 1478/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 126597.5703 - val_loss: 26958.1367\n",
      "Epoch 1479/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 121902.8750 - val_loss: 31763.3301\n",
      "Epoch 1480/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 127388.5703 - val_loss: 35257.4648\n",
      "Epoch 1481/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 124301.3906 - val_loss: 31585.5039\n",
      "Epoch 1482/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 124631.2578 - val_loss: 28886.4316\n",
      "Epoch 1483/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 136581.0781 - val_loss: 30781.5918\n",
      "Epoch 1484/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 130550.5000 - val_loss: 28586.5684\n",
      "Epoch 1485/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 127031.6406 - val_loss: 29430.6387\n",
      "Epoch 1486/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 121270.6641 - val_loss: 29049.2578\n",
      "Epoch 1487/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 124010.6250 - val_loss: 29258.4961\n",
      "Epoch 1488/5000\n",
      "8/8 [==============================] - 6s 768ms/step - loss: 124508.2969 - val_loss: 26435.2383\n",
      "Epoch 1489/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 128344.7734 - val_loss: 24460.0664\n",
      "Epoch 1490/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 119717.7656 - val_loss: 28843.6875\n",
      "Epoch 1491/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 130637.3594 - val_loss: 31789.1504\n",
      "Epoch 1492/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 129241.1797 - val_loss: 31107.7949\n",
      "Epoch 1493/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 132920.9219 - val_loss: 28388.2637\n",
      "Epoch 1494/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 138734.5938 - val_loss: 36674.9961\n",
      "Epoch 1495/5000\n",
      "8/8 [==============================] - 7s 871ms/step - loss: 135097.4062 - val_loss: 35197.6602\n",
      "Epoch 1496/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 131807.0312 - val_loss: 30770.3613\n",
      "Epoch 1497/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 135894.4688 - val_loss: 29696.9941\n",
      "Epoch 1498/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 135364.1875 - val_loss: 27882.1191\n",
      "Epoch 1499/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 133062.0469 - val_loss: 29753.0918\n",
      "Epoch 1500/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 124796.8047 - val_loss: 28229.5020\n",
      "Epoch 1501/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 123084.0859 - val_loss: 26549.7051\n",
      "Epoch 1502/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 127905.6406 - val_loss: 27638.4238\n",
      "Epoch 1503/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 128931.7031 - val_loss: 28355.6250\n",
      "Epoch 1504/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 129690.9453 - val_loss: 30365.3926\n",
      "Epoch 1505/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 134291.8594 - val_loss: 26253.3184\n",
      "Epoch 1506/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 137614.4062 - val_loss: 33775.7734\n",
      "Epoch 1507/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 142311.0000 - val_loss: 27981.2793\n",
      "Epoch 1508/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 132526.0156 - val_loss: 32661.5723\n",
      "Epoch 1509/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 145456.3281 - val_loss: 29868.9121\n",
      "Epoch 1510/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 136260.9688 - val_loss: 27614.4609\n",
      "Epoch 1511/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 124705.8828 - val_loss: 27231.6934\n",
      "Epoch 1512/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 128302.8359 - val_loss: 24355.6582\n",
      "Epoch 1513/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 129357.3828 - val_loss: 26898.4590\n",
      "Epoch 1514/5000\n",
      "8/8 [==============================] - 6s 766ms/step - loss: 136923.3281 - val_loss: 26436.8496\n",
      "Epoch 1515/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 132574.7188 - val_loss: 27444.6328\n",
      "Epoch 1516/5000\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 132822.4062 - val_loss: 29954.4824\n",
      "Epoch 1517/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 142033.3906 - val_loss: 25190.1289\n",
      "Epoch 1518/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 137456.2812 - val_loss: 31509.8496\n",
      "Epoch 1519/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 140969.1875 - val_loss: 31515.8379\n",
      "Epoch 1520/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 154742.6406 - val_loss: 39071.6875\n",
      "Epoch 1521/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 155384.0312 - val_loss: 27874.7305\n",
      "Epoch 1522/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 153353.5469 - val_loss: 31302.9434\n",
      "Epoch 1523/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 139259.2656 - val_loss: 30740.6133\n",
      "Epoch 1524/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 150968.3125 - val_loss: 31920.4707\n",
      "Epoch 1525/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 141126.4375 - val_loss: 30271.7598\n",
      "Epoch 1526/5000\n",
      "8/8 [==============================] - 6s 765ms/step - loss: 142500.5781 - val_loss: 28947.2500\n",
      "Epoch 1527/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 140090.2812 - val_loss: 27023.1777\n",
      "Epoch 1528/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 129980.5781 - val_loss: 28055.7305\n",
      "Epoch 1529/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 128260.0859 - val_loss: 34520.7422\n",
      "Epoch 1530/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 145272.1875 - val_loss: 29843.3184\n",
      "Epoch 1531/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 141523.2344 - val_loss: 29674.5000\n",
      "Epoch 1532/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 146524.0469 - val_loss: 29874.0254\n",
      "Epoch 1533/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 144030.4375 - val_loss: 38705.7695\n",
      "Epoch 1534/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 170278.3125 - val_loss: 30143.0195\n",
      "Epoch 1535/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 141315.6094 - val_loss: 27916.4199\n",
      "Epoch 1536/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 160653.1562 - val_loss: 36366.2227\n",
      "Epoch 1537/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 153814.2188 - val_loss: 30282.1074\n",
      "Epoch 1538/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 139635.2344 - val_loss: 27553.0039\n",
      "Epoch 1539/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 138308.0625 - val_loss: 32908.7461\n",
      "Epoch 1540/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 140480.0000 - val_loss: 28560.9414\n",
      "Epoch 1541/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 144473.9844 - val_loss: 28970.9883\n",
      "Epoch 1542/5000\n",
      "8/8 [==============================] - 7s 843ms/step - loss: 140327.4531 - val_loss: 26408.6758\n",
      "Epoch 1543/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 134337.0156 - val_loss: 30024.4688\n",
      "Epoch 1544/5000\n",
      "8/8 [==============================] - 7s 815ms/step - loss: 144733.8438 - val_loss: 30760.4473\n",
      "Epoch 1545/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 160091.8594 - val_loss: 29334.4922\n",
      "Epoch 1546/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 780ms/step - loss: 139169.1719 - val_loss: 27638.0410\n",
      "Epoch 1547/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 139622.5156 - val_loss: 29782.5371\n",
      "Epoch 1548/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 137261.0000 - val_loss: 28472.3047\n",
      "Epoch 1549/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 136392.2188 - val_loss: 27423.3633\n",
      "Epoch 1550/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 135449.3438 - val_loss: 29256.6387\n",
      "Epoch 1551/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 130051.9844 - val_loss: 26182.2559\n",
      "Epoch 1552/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 134442.0938 - val_loss: 28176.9609\n",
      "Epoch 1553/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 132796.2812 - val_loss: 26037.4824\n",
      "Epoch 1554/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 124518.1797 - val_loss: 27654.7871\n",
      "Epoch 1555/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 127879.2812 - val_loss: 29346.6562\n",
      "Epoch 1556/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 138427.7500 - val_loss: 27992.9316\n",
      "Epoch 1557/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 134732.5156 - val_loss: 29172.4766\n",
      "Epoch 1558/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 131519.2188 - val_loss: 30735.3711\n",
      "Epoch 1559/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 132881.1094 - val_loss: 27214.7480\n",
      "Epoch 1560/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 131591.0625 - val_loss: 28871.1211\n",
      "Epoch 1561/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 136335.9375 - val_loss: 27947.7832\n",
      "Epoch 1562/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 136302.4375 - val_loss: 25531.4121\n",
      "Epoch 1563/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 136538.5625 - val_loss: 29807.2949\n",
      "Epoch 1564/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 136720.6562 - val_loss: 29750.8965\n",
      "Epoch 1565/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 132832.2656 - val_loss: 24056.4121\n",
      "Epoch 1566/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 131967.7656 - val_loss: 27133.4746\n",
      "Epoch 1567/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 137165.4531 - val_loss: 29555.7793\n",
      "Epoch 1568/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 131362.0156 - val_loss: 25211.9922\n",
      "Epoch 1569/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 127271.0469 - val_loss: 27484.1621\n",
      "Epoch 1570/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 124619.1641 - val_loss: 23577.2832\n",
      "Epoch 1571/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 129155.2734 - val_loss: 26069.3301\n",
      "Epoch 1572/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 132798.8438 - val_loss: 27349.0586\n",
      "Epoch 1573/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 133286.3594 - val_loss: 27381.1660\n",
      "Epoch 1574/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 127291.5234 - val_loss: 27158.6582\n",
      "Epoch 1575/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 127463.8594 - val_loss: 26258.5742\n",
      "Epoch 1576/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 129336.3281 - val_loss: 29456.8125\n",
      "Epoch 1577/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 137010.4062 - val_loss: 27322.2539\n",
      "Epoch 1578/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 127263.1094 - val_loss: 26375.6055\n",
      "Epoch 1579/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 130655.9609 - val_loss: 26403.1211\n",
      "Epoch 1580/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 124336.2734 - val_loss: 27138.3086\n",
      "Epoch 1581/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 124640.8203 - val_loss: 27686.3398\n",
      "Epoch 1582/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 128344.0000 - val_loss: 28506.7285\n",
      "Epoch 1583/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 131170.3438 - val_loss: 29624.2383\n",
      "Epoch 1584/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 127651.2969 - val_loss: 39000.2383\n",
      "Epoch 1585/5000\n",
      "8/8 [==============================] - 7s 836ms/step - loss: 125283.5469 - val_loss: 28610.9512\n",
      "Epoch 1586/5000\n",
      "8/8 [==============================] - 7s 864ms/step - loss: 133543.8125 - val_loss: 29563.0215\n",
      "Epoch 1587/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 123045.1641 - val_loss: 26807.9023\n",
      "Epoch 1588/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 126505.9141 - val_loss: 24517.0234\n",
      "Epoch 1589/5000\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 124331.0859 - val_loss: 27289.9570\n",
      "Epoch 1590/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 127061.4922 - val_loss: 27064.3457\n",
      "Epoch 1591/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 131768.4062 - val_loss: 30911.9082\n",
      "Epoch 1592/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 131833.4688 - val_loss: 25685.4902\n",
      "Epoch 1593/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 128485.4297 - val_loss: 25260.2852\n",
      "Epoch 1594/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 125781.8594 - val_loss: 27073.7930\n",
      "Epoch 1595/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 128178.2969 - val_loss: 31959.9629\n",
      "Epoch 1596/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 123817.1250 - val_loss: 27206.4375\n",
      "Epoch 1597/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 126135.0938 - val_loss: 28432.3926\n",
      "Epoch 1598/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 130001.0078 - val_loss: 23788.3125\n",
      "Epoch 1599/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 126054.8359 - val_loss: 26577.6836\n",
      "Epoch 1600/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 128612.1719 - val_loss: 25816.3926\n",
      "Epoch 1601/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 124553.5391 - val_loss: 24748.6348\n",
      "Epoch 1602/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 120095.6562 - val_loss: 24145.8887\n",
      "Epoch 1603/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 118735.3438 - val_loss: 26140.8125\n",
      "Epoch 1604/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 125661.2734 - val_loss: 27035.3008\n",
      "Epoch 1605/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 126393.7734 - val_loss: 26425.7852\n",
      "Epoch 1606/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 126152.7656 - val_loss: 25503.7148\n",
      "Epoch 1607/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 126365.7422 - val_loss: 25735.6289\n",
      "Epoch 1608/5000\n",
      "8/8 [==============================] - 6s 809ms/step - loss: 132008.4219 - val_loss: 25519.4727\n",
      "Epoch 1609/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 128230.0703 - val_loss: 27620.4941\n",
      "Epoch 1610/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 126601.5312 - val_loss: 27028.5879\n",
      "Epoch 1611/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 127807.6406 - val_loss: 24114.5254\n",
      "Epoch 1612/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 126197.8047 - val_loss: 28720.6875\n",
      "Epoch 1613/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 125057.5234 - val_loss: 26538.3008\n",
      "Epoch 1614/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 139262.8438 - val_loss: 36042.4805\n",
      "Epoch 1615/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 133666.9062 - val_loss: 35943.0234\n",
      "Epoch 1616/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 137979.4219 - val_loss: 26547.4824\n",
      "Epoch 1617/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 125536.3516 - val_loss: 27644.8945\n",
      "Epoch 1618/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 131368.9844 - val_loss: 24991.6660\n",
      "Epoch 1619/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 777ms/step - loss: 132219.9844 - val_loss: 24515.6250\n",
      "Epoch 1620/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 132048.7812 - val_loss: 26154.4199\n",
      "Epoch 1621/5000\n",
      "8/8 [==============================] - 6s 767ms/step - loss: 126725.6484 - val_loss: 27170.9492\n",
      "Epoch 1622/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 123913.8281 - val_loss: 30315.6621\n",
      "Epoch 1623/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 133337.4688 - val_loss: 29790.4785\n",
      "Epoch 1624/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 129066.7031 - val_loss: 28477.3340\n",
      "Epoch 1625/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 123895.4844 - val_loss: 26311.2754\n",
      "Epoch 1626/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 122488.0547 - val_loss: 23599.9258\n",
      "Epoch 1627/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 123277.5156 - val_loss: 25991.4727\n",
      "Epoch 1628/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 123481.0703 - val_loss: 28240.1172\n",
      "Epoch 1629/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 123497.2266 - val_loss: 29681.0664\n",
      "Epoch 1630/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 124221.9688 - val_loss: 25756.7285\n",
      "Epoch 1631/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 131593.0938 - val_loss: 28841.6465\n",
      "Epoch 1632/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 127207.0312 - val_loss: 27664.6523\n",
      "Epoch 1633/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 124468.6641 - val_loss: 27772.5410\n",
      "Epoch 1634/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 125634.0781 - val_loss: 29242.1133\n",
      "Epoch 1635/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 134762.6094 - val_loss: 28793.1250\n",
      "Epoch 1636/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 132256.3594 - val_loss: 28583.9512\n",
      "Epoch 1637/5000\n",
      "8/8 [==============================] - 6s 810ms/step - loss: 130314.2812 - val_loss: 28022.7578\n",
      "Epoch 1638/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 128024.2656 - val_loss: 29624.0234\n",
      "Epoch 1639/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 125286.7812 - val_loss: 28958.9199\n",
      "Epoch 1640/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 125644.0391 - val_loss: 25771.6484\n",
      "Epoch 1641/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 121553.5547 - val_loss: 25269.3535\n",
      "Epoch 1642/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 122691.3672 - val_loss: 25268.1621\n",
      "Epoch 1643/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 124654.0156 - val_loss: 27742.0508\n",
      "Epoch 1644/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 127077.7500 - val_loss: 27509.9238\n",
      "Epoch 1645/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 122693.6953 - val_loss: 25735.7676\n",
      "Epoch 1646/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 123986.4688 - val_loss: 24497.0977\n",
      "Epoch 1647/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 127172.9844 - val_loss: 28607.3672\n",
      "Epoch 1648/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 126150.8359 - val_loss: 36242.3047\n",
      "Epoch 1649/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 132318.8906 - val_loss: 27848.4668\n",
      "Epoch 1650/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 123648.4297 - val_loss: 29290.8750\n",
      "Epoch 1651/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 128297.9844 - val_loss: 24321.8926\n",
      "Epoch 1652/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 118855.9688 - val_loss: 26854.6660\n",
      "Epoch 1653/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 121418.2188 - val_loss: 27062.9590\n",
      "Epoch 1654/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 122129.5000 - val_loss: 27667.9414\n",
      "Epoch 1655/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 128908.4141 - val_loss: 29086.4824\n",
      "Epoch 1656/5000\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 130148.4141 - val_loss: 27167.6230\n",
      "Epoch 1657/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 128090.7031 - val_loss: 28724.3926\n",
      "Epoch 1658/5000\n",
      "8/8 [==============================] - 6s 768ms/step - loss: 126504.0391 - val_loss: 28597.5977\n",
      "Epoch 1659/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 138599.6875 - val_loss: 27377.4395\n",
      "Epoch 1660/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 131217.5000 - val_loss: 28350.7559\n",
      "Epoch 1661/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 133992.9531 - val_loss: 27690.4609\n",
      "Epoch 1662/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 125333.6641 - val_loss: 37481.2266\n",
      "Epoch 1663/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 142379.3594 - val_loss: 33733.7656\n",
      "Epoch 1664/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 138409.0469 - val_loss: 25255.1426\n",
      "Epoch 1665/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 139615.2969 - val_loss: 30727.9375\n",
      "Epoch 1666/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 139579.0781 - val_loss: 28716.8984\n",
      "Epoch 1667/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 135346.3438 - val_loss: 27635.7617\n",
      "Epoch 1668/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 129537.5781 - val_loss: 26640.2012\n",
      "Epoch 1669/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 127413.8750 - val_loss: 25292.3340\n",
      "Epoch 1670/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 129887.9844 - val_loss: 29151.2832\n",
      "Epoch 1671/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 134025.4844 - val_loss: 27700.8613\n",
      "Epoch 1672/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 128506.2109 - val_loss: 27938.0508\n",
      "Epoch 1673/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 129512.4062 - val_loss: 30736.1875\n",
      "Epoch 1674/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 138655.0781 - val_loss: 29367.0137\n",
      "Epoch 1675/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 132204.0625 - val_loss: 27611.7871\n",
      "Epoch 1676/5000\n",
      "8/8 [==============================] - 6s 763ms/step - loss: 135680.2656 - val_loss: 29932.6621\n",
      "Epoch 1677/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 139274.5312 - val_loss: 29854.9883\n",
      "Epoch 1678/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 131744.7031 - val_loss: 26522.1660\n",
      "Epoch 1679/5000\n",
      "8/8 [==============================] - 6s 809ms/step - loss: 123951.3516 - val_loss: 26456.2539\n",
      "Epoch 1680/5000\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 132490.3594 - val_loss: 28820.0254\n",
      "Epoch 1681/5000\n",
      "8/8 [==============================] - 7s 826ms/step - loss: 140035.1562 - val_loss: 30082.4141\n",
      "Epoch 1682/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 141317.9688 - val_loss: 26302.4375\n",
      "Epoch 1683/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 132119.7969 - val_loss: 25415.0645\n",
      "Epoch 1684/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 134998.7344 - val_loss: 28182.4375\n",
      "Epoch 1685/5000\n",
      "8/8 [==============================] - 9s 1s/step - loss: 135115.3906 - val_loss: 26212.8496\n",
      "Epoch 1686/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 132877.4062 - val_loss: 31589.4863\n",
      "Epoch 1687/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 139519.9844 - val_loss: 27839.0957\n",
      "Epoch 1688/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 133292.1406 - val_loss: 25893.7461\n",
      "Epoch 1689/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 142627.4375 - val_loss: 29775.3086\n",
      "Epoch 1690/5000\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 142111.6406 - val_loss: 36899.0469\n",
      "Epoch 1691/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 155130.4375 - val_loss: 28689.4551\n",
      "Epoch 1692/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 797ms/step - loss: 146292.9062 - val_loss: 29996.0117\n",
      "Epoch 1693/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 143710.5469 - val_loss: 30587.7227\n",
      "Epoch 1694/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 136671.5469 - val_loss: 29848.1035\n",
      "Epoch 1695/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 145240.3281 - val_loss: 27808.5879\n",
      "Epoch 1696/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 129668.7344 - val_loss: 28982.1465\n",
      "Epoch 1697/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 131772.0625 - val_loss: 27013.8184\n",
      "Epoch 1698/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 139001.3594 - val_loss: 29967.4062\n",
      "Epoch 1699/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 140683.7969 - val_loss: 28293.8984\n",
      "Epoch 1700/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 131762.1875 - val_loss: 27532.9492\n",
      "Epoch 1701/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 135565.9219 - val_loss: 26396.3535\n",
      "Epoch 1702/5000\n",
      "8/8 [==============================] - 7s 816ms/step - loss: 137685.5625 - val_loss: 27455.9961\n",
      "Epoch 1703/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 134502.2188 - val_loss: 29171.9609\n",
      "Epoch 1704/5000\n",
      "8/8 [==============================] - 7s 815ms/step - loss: 141641.2969 - val_loss: 27403.0117\n",
      "Epoch 1705/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 133588.5000 - val_loss: 26396.1621\n",
      "Epoch 1706/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 141580.4844 - val_loss: 31605.9961\n",
      "Epoch 1707/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 144057.8594 - val_loss: 29500.6914\n",
      "Epoch 1708/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 137713.0938 - val_loss: 29569.2168\n",
      "Epoch 1709/5000\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 143694.4531 - val_loss: 27409.1875\n",
      "Epoch 1710/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 132797.1094 - val_loss: 30537.1543\n",
      "Epoch 1711/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 141683.3125 - val_loss: 26852.1484\n",
      "Epoch 1712/5000\n",
      "8/8 [==============================] - 7s 894ms/step - loss: 135845.1875 - val_loss: 28684.0840\n",
      "Epoch 1713/5000\n",
      "8/8 [==============================] - 7s 825ms/step - loss: 134847.0781 - val_loss: 26973.3301\n",
      "Epoch 1714/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 134801.6719 - val_loss: 28833.7578\n",
      "Epoch 1715/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 133047.4688 - val_loss: 24772.4492\n",
      "Epoch 1716/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 133040.5625 - val_loss: 28602.7461\n",
      "Epoch 1717/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 131350.7500 - val_loss: 27272.5723\n",
      "Epoch 1718/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 130100.0078 - val_loss: 28078.9004\n",
      "Epoch 1719/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 133116.4688 - val_loss: 24445.9414\n",
      "Epoch 1720/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 130672.4062 - val_loss: 27082.5312\n",
      "Epoch 1721/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 126853.1406 - val_loss: 24878.2480\n",
      "Epoch 1722/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 127207.5234 - val_loss: 26748.7012\n",
      "Epoch 1723/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 128974.6719 - val_loss: 28368.9434\n",
      "Epoch 1724/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 139730.4375 - val_loss: 28303.2910\n",
      "Epoch 1725/5000\n",
      "8/8 [==============================] - 6s 809ms/step - loss: 129369.7969 - val_loss: 25583.7227\n",
      "Epoch 1726/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 131000.0703 - val_loss: 27607.1172\n",
      "Epoch 1727/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 126350.0703 - val_loss: 26678.4180\n",
      "Epoch 1728/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 122312.3906 - val_loss: 27786.8535\n",
      "Epoch 1729/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 129675.5859 - val_loss: 25445.8340\n",
      "Epoch 1730/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 131120.2188 - val_loss: 26138.7832\n",
      "Epoch 1731/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 136107.0938 - val_loss: 28855.6543\n",
      "Epoch 1732/5000\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 132009.3125 - val_loss: 29028.0996\n",
      "Epoch 1733/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 134117.7969 - val_loss: 25547.6289\n",
      "Epoch 1734/5000\n",
      "8/8 [==============================] - 6s 768ms/step - loss: 132030.4219 - val_loss: 29183.9805\n",
      "Epoch 1735/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 139548.2812 - val_loss: 29603.3086\n",
      "Epoch 1736/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 131730.5938 - val_loss: 27280.6172\n",
      "Epoch 1737/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 132042.0156 - val_loss: 27416.9141\n",
      "Epoch 1738/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 135706.4531 - val_loss: 27532.9043\n",
      "Epoch 1739/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 129653.9219 - val_loss: 32097.2734\n",
      "Epoch 1740/5000\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 133369.0625 - val_loss: 27763.1758\n",
      "Epoch 1741/5000\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 131273.7969 - val_loss: 25647.2910\n",
      "Epoch 1742/5000\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 124626.5000 - val_loss: 27314.9277\n",
      "Epoch 1743/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 130896.3047 - val_loss: 30971.7988\n",
      "Epoch 1744/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 134283.0938 - val_loss: 29725.5918\n",
      "Epoch 1745/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 129932.4531 - val_loss: 33083.7539\n",
      "Epoch 1746/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 139172.4062 - val_loss: 28865.9590\n",
      "Epoch 1747/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 131832.0469 - val_loss: 24391.5703\n",
      "Epoch 1748/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 129271.9844 - val_loss: 27704.2090\n",
      "Epoch 1749/5000\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 132028.9219 - val_loss: 25339.1777\n",
      "Epoch 1750/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 126947.7031 - val_loss: 28553.2559\n",
      "Epoch 1751/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 135383.6719 - val_loss: 29625.9297\n",
      "Epoch 1752/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 130161.3281 - val_loss: 25875.1758\n",
      "Epoch 1753/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 133065.1094 - val_loss: 24000.6504\n",
      "Epoch 1754/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 123570.3672 - val_loss: 26487.8789\n",
      "Epoch 1755/5000\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 127881.5781 - val_loss: 28717.1621\n",
      "Epoch 1756/5000\n",
      "8/8 [==============================] - 6s 771ms/step - loss: 134927.7656 - val_loss: 27348.7305\n",
      "Epoch 1757/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 134372.5781 - val_loss: 25332.7461\n",
      "Epoch 1758/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 129797.7188 - val_loss: 25855.8926\n",
      "Epoch 1759/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 134586.9531 - val_loss: 27959.0449\n",
      "Epoch 1760/5000\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 134890.7812 - val_loss: 27214.3301\n",
      "Epoch 1761/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 130625.7344 - val_loss: 27937.5039\n",
      "Epoch 1762/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 132551.5625 - val_loss: 27353.0703\n",
      "Epoch 1763/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 141799.0469 - val_loss: 30083.9980\n",
      "Epoch 1764/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 134635.6719 - val_loss: 26300.5332\n",
      "Epoch 1765/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 792ms/step - loss: 137864.0625 - val_loss: 27454.5586\n",
      "Epoch 1766/5000\n",
      "8/8 [==============================] - 6s 769ms/step - loss: 138300.5156 - val_loss: 31894.2617\n",
      "Epoch 1767/5000\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 141432.3594 - val_loss: 30420.3555\n",
      "Epoch 1768/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 138721.8438 - val_loss: 26022.8184\n",
      "Epoch 1769/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 145218.5312 - val_loss: 25501.2129\n",
      "Epoch 1770/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 130659.4531 - val_loss: 30513.0176\n",
      "Epoch 1771/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 137112.3438 - val_loss: 26582.7871\n",
      "Epoch 1772/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 126208.6484 - val_loss: 27101.5625\n",
      "Epoch 1773/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 128633.6094 - val_loss: 27420.3711\n",
      "Epoch 1774/5000\n",
      "8/8 [==============================] - 6s 766ms/step - loss: 139329.8906 - val_loss: 28280.5547\n",
      "Epoch 1775/5000\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 140778.1719 - val_loss: 26897.3203\n",
      "Epoch 1776/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 136699.1250 - val_loss: 26657.9277\n",
      "Epoch 1777/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 138452.3594 - val_loss: 28057.8652\n",
      "Epoch 1778/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 136654.5469 - val_loss: 25800.0664\n",
      "Epoch 1779/5000\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 128929.8438 - val_loss: 24882.8770\n",
      "Epoch 1780/5000\n",
      "8/8 [==============================] - 7s 814ms/step - loss: 125546.2656 - val_loss: 25366.2402\n",
      "Epoch 1781/5000\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 127964.1484 - val_loss: 26554.1621\n",
      "Epoch 1782/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 131433.6406 - val_loss: 28899.1777\n",
      "Epoch 1783/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 138273.0469 - val_loss: 26303.0938\n",
      "Epoch 1784/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 138393.9688 - val_loss: 27166.5801\n",
      "Epoch 1785/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 164487.2812 - val_loss: 30867.3125\n",
      "Epoch 1786/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 146823.9531 - val_loss: 32408.5547\n",
      "Epoch 1787/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 148286.5000 - val_loss: 33137.2773\n",
      "Epoch 1788/5000\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 145221.4375 - val_loss: 29930.6582\n",
      "Epoch 1789/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 149672.5312 - val_loss: 30026.5703\n",
      "Epoch 1790/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 146057.0312 - val_loss: 27153.6055\n",
      "Epoch 1791/5000\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 138798.6719 - val_loss: 26790.7539\n",
      "Epoch 1792/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 140110.2031 - val_loss: 28787.3789\n",
      "Epoch 1793/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 134340.3594 - val_loss: 25609.4668\n",
      "Epoch 1794/5000\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 131157.0469 - val_loss: 27099.6074\n",
      "Epoch 1795/5000\n",
      "8/8 [==============================] - 7s 847ms/step - loss: 130632.2969 - val_loss: 25659.9043\n",
      "Epoch 1796/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 129938.1719 - val_loss: 30161.5254\n",
      "Epoch 1797/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 134010.3594 - val_loss: 27746.5723\n",
      "Epoch 1798/5000\n",
      "8/8 [==============================] - 7s 813ms/step - loss: 127153.5938 - val_loss: 26667.2422\n",
      "Epoch 1799/5000\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 127593.2891 - val_loss: 28110.6172\n",
      "Epoch 1800/5000\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 129705.3672 - val_loss: 23973.0098\n",
      "Epoch 1801/5000\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 129243.4531 - val_loss: 26266.4551\n",
      "Epoch 1802/5000\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 131604.7656 - val_loss: 28247.7754\n",
      "Epoch 1803/5000\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 132079.5938 - val_loss: 26574.1191\n",
      "Epoch 1804/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 134061.8281 - val_loss: 30266.9004\n",
      "Epoch 1805/5000\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 134788.4531 - val_loss: 28670.7285\n",
      "Epoch 1806/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 132856.3438 - val_loss: 29910.0117\n",
      "Epoch 1807/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 133746.7188 - val_loss: 29557.0664\n",
      "Epoch 1808/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 131785.4219 - val_loss: 25137.4180\n",
      "Epoch 1809/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 124365.4609 - val_loss: 25874.5859\n",
      "Epoch 1810/5000\n",
      "8/8 [==============================] - 6s 795ms/step - loss: 127493.0000 - val_loss: 25349.5078\n",
      "Epoch 1811/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 129896.2109 - val_loss: 26546.2168\n",
      "Epoch 1812/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 131262.4219 - val_loss: 26082.3086\n",
      "Epoch 1813/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 125975.5781 - val_loss: 27797.7578\n",
      "Epoch 1814/5000\n",
      "8/8 [==============================] - 7s 813ms/step - loss: 131544.9062 - val_loss: 27270.9199\n",
      "Epoch 1815/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 124377.7344 - val_loss: 29276.9863\n",
      "Epoch 1816/5000\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 131191.9844 - val_loss: 25931.3086\n",
      "Epoch 1817/5000\n",
      "8/8 [==============================] - 6s 793ms/step - loss: 129751.4766 - val_loss: 24746.9570\n",
      "Epoch 1818/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 131524.9219 - val_loss: 25056.8340\n",
      "Epoch 1819/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 131002.4219 - val_loss: 26168.9453\n",
      "Epoch 1820/5000\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 124374.8984 - val_loss: 25166.2070\n",
      "Epoch 1821/5000\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 127822.4922 - val_loss: 27239.0020\n",
      "Epoch 1822/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 127741.3516 - val_loss: 25290.8750\n",
      "Epoch 1823/5000\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 127375.3438 - val_loss: 27024.0371\n",
      "Epoch 1824/5000\n",
      "8/8 [==============================] - 6s 811ms/step - loss: 131147.7812 - val_loss: 28913.5859\n",
      "Epoch 1825/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 131268.3750 - val_loss: 23893.9082\n",
      "Epoch 1826/5000\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 123612.8047 - val_loss: 29052.9668\n",
      "Epoch 1827/5000\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 133540.7188 - val_loss: 24536.7598\n",
      "Epoch 1828/5000\n",
      "8/8 [==============================] - 6s 800ms/step - loss: 126688.5469 - val_loss: 31668.7773\n",
      "Epoch 1829/5000\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 134321.1719 - val_loss: 27550.5742\n",
      "Epoch 1830/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 131436.9375 - val_loss: 27705.3203\n",
      "Epoch 1831/5000\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 128994.4453 - val_loss: 26485.0547\n",
      "Epoch 1832/5000\n",
      "8/8 [==============================] - 6s 802ms/step - loss: 126028.3672 - val_loss: 26274.1680\n",
      "Epoch 1833/5000\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 125404.3359 - val_loss: 29105.7754\n",
      "Epoch 1834/5000\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 125541.2656 - val_loss: 30046.3027\n",
      "Epoch 1835/5000\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 118127.3281 - val_loss: 25846.1582\n",
      "Epoch 1836/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 126043.4297 - val_loss: 25620.8125\n",
      "Epoch 1837/5000\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 127374.6797 - val_loss: 28556.4922\n",
      "Epoch 1838/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 798ms/step - loss: 133382.0312 - val_loss: 28144.5703\n",
      "Epoch 1839/5000\n",
      "8/8 [==============================] - 7s 912ms/step - loss: 124085.0156 - val_loss: 24388.1758\n",
      "Epoch 1840/5000\n",
      "8/8 [==============================] - 7s 840ms/step - loss: 127202.9062 - val_loss: 28030.9590\n",
      "Epoch 1841/5000\n",
      "8/8 [==============================] - 11s 1s/step - loss: 129171.9141 - val_loss: 27492.4707\n",
      "Epoch 1842/5000\n",
      "8/8 [==============================] - ETA: 0s - loss: 126115.5156"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e8febff1adeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    860\u001b[0m           val_x, val_y, val_sample_weight = (\n\u001b[1;32m    861\u001b[0m               data_adapter.unpack_x_y_sample_weight(validation_data))\n\u001b[0;32m--> 862\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    863\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(input_shape = (465,300), units = 465, activation = 'tanh'))\n",
    "model.add(Dense(465, activation = 'tanh'))\n",
    "model.add(Dense(465, activation = 'tanh'))\n",
    "model.add(Dense(465, activation = 'tanh'))\n",
    "model.add(Dense(465, activation = 'tanh'))\n",
    "model.add(Dense(465, activation = 'tanh'))\n",
    "model.add(Dense(300, activation = 'tanh'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "model.compile(loss = mpe, optimizer = opt)\n",
    "history = model.fit(rdfs, pots, epochs = 5000, batch_size = 30, verbose = 1, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-samba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "controlling-genealogy",
   "metadata": {},
   "source": [
    "## Testing the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exempt-zealand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-20.0, 20.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 214\n",
    "test = np.array([rdfs[i]])\n",
    "\n",
    "modelpred = model.predict([test])\n",
    "plt.plot(x, pots[i][0], label = 'Target')\n",
    "plt.plot(x, modelpred[0][0], label = 'Predict')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim(-20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-straight",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
